{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label text classification\n",
        "\n",
        "**Author:** [Farrokh Karimi](https://farrokhkarimi.github.io/)  \n",
        "**Description:** In this notebook, we want to classify the Ronash dataset into 20 category."
      ],
      "metadata": {
        "id": "Bij91pNWQOR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "sL739kMAEsU9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading Data from the Google Drive link\n",
        "!gdown 1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHa9m3aLEbyP",
        "outputId": "963fdcf0-9e0e-481d-c71d-8c87c57dae59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy\n",
            "To: /content/Ronash_DS_Assignment.csv\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 38.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QpBuoWrC5QS",
        "outputId": "6b6120e3-e960-4066-fec3-962d6363703b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ronash_DS_Assignment.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the csv file as a dataframe\n",
        "df = pd.read_csv('Ronash_DS_Assignment.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "722bMOmzF4_H",
        "outputId": "9f88c228-ce9d-4d8f-d50d-374394f26486"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         product_id                                              title  \\\n",
              "0     3937721221199    Fidele Super Premium Adult Large Breed Dog Food   \n",
              "1     7353058033889                    Foldable Pet Toys Linen Storage   \n",
              "2     6594773549129                                     Bok Dok Diaper   \n",
              "3     4802008318014                              Tastybone Toy Chicken   \n",
              "4     1779705151539                Leather Leash Tab - Short Dog Leash   \n",
              "...             ...                                                ...   \n",
              "5265  4637089464407                              Candylab MOO Milk Van   \n",
              "5266  4996632444987  Truck - Modern Era Vehicles -- Red, White -  S...   \n",
              "5267  5528541003927  Car Sticker Flags Decal American Flag Sticker for   \n",
              "5268  1395163889730          Lazer Helmets Bayamo Pit Bull - Full Face   \n",
              "5269  3535679324240                             Deutz Agrotron Tractor   \n",
              "\n",
              "                 vendor                                               tags  \\\n",
              "0                Fidele  ['Adult', 'Bangalore', 'Chennai', 'Chicken', '...   \n",
              "1             Cap Point                                                 []   \n",
              "2             Pets Home  ['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...   \n",
              "3             TastyBone                                                 []   \n",
              "4            Mighty Paw                 ['Leash', 'Leash Tab', 'Training']   \n",
              "...                 ...                                                ...   \n",
              "5265           Candylab  ['3 Years +', 'candylab', 'Discount Products',...   \n",
              "5266   Woodland Scenics  ['HO Scale', 'ho-scale-items', 'vehicles', 'wo...   \n",
              "5267        Cyan Selene                                          ['Other']   \n",
              "5268  OPEN BOX BARGAINS  ['65061090', 'Antiscratch Pinlock Ready Visor'...   \n",
              "5269               Siku  ['$0 to $25', 'diecast-models', 'gift-finder',...   \n",
              "\n",
              "                    category  \n",
              "0     Animals & Pet Supplies  \n",
              "1     Animals & Pet Supplies  \n",
              "2     Animals & Pet Supplies  \n",
              "3     Animals & Pet Supplies  \n",
              "4     Animals & Pet Supplies  \n",
              "...                      ...  \n",
              "5265        Vehicles & Parts  \n",
              "5266        Vehicles & Parts  \n",
              "5267        Vehicles & Parts  \n",
              "5268        Vehicles & Parts  \n",
              "5269        Vehicles & Parts  \n",
              "\n",
              "[5270 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-279c5ece-0737-47e3-9164-957327a1ea1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>title</th>\n",
              "      <th>vendor</th>\n",
              "      <th>tags</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3937721221199</td>\n",
              "      <td>Fidele Super Premium Adult Large Breed Dog Food</td>\n",
              "      <td>Fidele</td>\n",
              "      <td>['Adult', 'Bangalore', 'Chennai', 'Chicken', '...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7353058033889</td>\n",
              "      <td>Foldable Pet Toys Linen Storage</td>\n",
              "      <td>Cap Point</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6594773549129</td>\n",
              "      <td>Bok Dok Diaper</td>\n",
              "      <td>Pets Home</td>\n",
              "      <td>['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4802008318014</td>\n",
              "      <td>Tastybone Toy Chicken</td>\n",
              "      <td>TastyBone</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1779705151539</td>\n",
              "      <td>Leather Leash Tab - Short Dog Leash</td>\n",
              "      <td>Mighty Paw</td>\n",
              "      <td>['Leash', 'Leash Tab', 'Training']</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>4637089464407</td>\n",
              "      <td>Candylab MOO Milk Van</td>\n",
              "      <td>Candylab</td>\n",
              "      <td>['3 Years +', 'candylab', 'Discount Products',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>4996632444987</td>\n",
              "      <td>Truck - Modern Era Vehicles -- Red, White -  S...</td>\n",
              "      <td>Woodland Scenics</td>\n",
              "      <td>['HO Scale', 'ho-scale-items', 'vehicles', 'wo...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>5528541003927</td>\n",
              "      <td>Car Sticker Flags Decal American Flag Sticker for</td>\n",
              "      <td>Cyan Selene</td>\n",
              "      <td>['Other']</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>1395163889730</td>\n",
              "      <td>Lazer Helmets Bayamo Pit Bull - Full Face</td>\n",
              "      <td>OPEN BOX BARGAINS</td>\n",
              "      <td>['65061090', 'Antiscratch Pinlock Ready Visor'...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>3535679324240</td>\n",
              "      <td>Deutz Agrotron Tractor</td>\n",
              "      <td>Siku</td>\n",
              "      <td>['$0 to $25', 'diecast-models', 'gift-finder',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-279c5ece-0737-47e3-9164-957327a1ea1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-279c5ece-0737-47e3-9164-957327a1ea1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-279c5ece-0737-47e3-9164-957327a1ea1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of each label\n",
        "df['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E1ZDXyPlr6y",
        "outputId": "54b9e544-e475-4384-d001-ed64ebaf7cf7"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Apparel & Accessories        1000\n",
              "Animals & Pet Supplies        500\n",
              "Food, Beverages & Tobacco     400\n",
              "Sporting Goods                400\n",
              "Luggage & Bags                400\n",
              "Home & Garden                 400\n",
              "Health & Beauty               400\n",
              "Media                         300\n",
              "Toys & Games                  300\n",
              "Furniture                     200\n",
              "Baby & Toddler                200\n",
              "Arts & Entertainment          200\n",
              "Electronics                   100\n",
              "Business & Industrial         100\n",
              "Office Supplies               100\n",
              "Vehicles & Parts              100\n",
              "Hardware                       50\n",
              "Cameras & Optics               50\n",
              "Software                       50\n",
              "Religious & Ceremonial         20\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting how many indices are duplicated in each column\n",
        "print(f\"There are {sum(df['title'].duplicated())} duplicate title.\")\n",
        "print(f\"There are {sum(df['vendor'].duplicated())} duplicate vondor.\")\n",
        "print(f\"There are {sum(df['tags'].duplicated())} duplicate tags.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_ggKoLUAEf",
        "outputId": "f3cafade-0ca9-47dd-e05e-99892df847e0"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 duplicate title.\n",
            "There are 1256 duplicate vondor.\n",
            "There are 716 duplicate tags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of Nan samples\n",
        "df.isnull().values.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD95efZwCRYT",
        "outputId": "bc7ee866-cac5-42cd-a0cf-b16bb214e951"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are just 3 Nan samples in the dataset so we can ignore them."
      ],
      "metadata": {
        "id": "rhPJQuDEb8oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the function for extracting and standardizing the sentences\n",
        "def text_extraction(dfi):\n",
        "  # in this function, we concatenate text feature parts of the data as a sentence\n",
        "  sentence = ' '.join([dfi['title'], str(dfi['vendor']), dfi['tags']])\n",
        "  # Remove punctuations\n",
        "  sentence = re.sub('[^a-zA-Z0-9$.]', ' ', sentence)\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "  # Changint to lowercase\n",
        "  sentence = sentence.lower()\n",
        "  return sentence\n",
        "\n",
        "# printing 10 sample sentences\n",
        "for i in range(10):\n",
        "  print(text_extraction(df.iloc[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH9UzP7-__P2",
        "outputId": "7b61119f-faef-4cdd-e9d9-110721da9755"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fidele super premium adult large breed dog food fidele adult bangalore chennai chicken doberman dog dry foods fidele german shepherd golden retriever great dane highpriority imported labrador less than 1000 less than 2000 less than 500 mastiff orange pet nutrition \n",
            "foldable pet toys linen storage cap point \n",
            "bok dok diaper pets home brand pet arabia category pets home category small pets supplies type pet home type pet supplies \n",
            "tastybone toy chicken tastybone \n",
            "leather leash tab short dog leash mighty paw leash leash tab training \n",
            "pridebites texas guitar dog toy pride bites brand pridebites toy type plush \n",
            "burns sensitive pork potato burns 10 25 25 50 50 75 adult burns coat dog food food delivery jansale18 natural nonsale19 sensitive size 12kg size 2kg size 6kg skin \n",
            "bully sticks dog toy adog.co bully sticks dog chew toys dog toys \n",
            "kazoo tough giraffe dog toy kazoo brand kazoo june2021 kazoo material plush plush \n",
            "orgo dog biscuits fresh milk petku brand orgo category dogs dogs lifestage all lifestages orgo price rp 0 to rp 100.000 subcategory treats treats \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the dataset\n",
        "dataset = pd.DataFrame(columns=['text', 'label'])\n",
        "for i in range(len(df)):\n",
        "  dataset = dataset.append({'text':text_extraction(df.iloc[i]), 'label':df.iloc[i]['category']}, ignore_index = True)\n",
        "\n",
        "# creating integer labels for multiclass training\n",
        "dataset['label_int'] = pd.Categorical(dataset['label']).codes\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7x4WG7NC9Xz3",
        "outputId": "1c562512-c146-4995-c08b-976a7d8bd249"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0     fidele super premium adult large breed dog foo...   \n",
              "1            foldable pet toys linen storage cap point    \n",
              "2     bok dok diaper pets home brand pet arabia cate...   \n",
              "3                      tastybone toy chicken tastybone    \n",
              "4     leather leash tab short dog leash mighty paw l...   \n",
              "...                                                 ...   \n",
              "5265  candylab moo milk van candylab 3 years candyla...   \n",
              "5266  truck modern era vehicles red white scale ho w...   \n",
              "5267  car sticker flags decal american flag sticker ...   \n",
              "5268  lazer helmets bayamo pit bull full face open b...   \n",
              "5269  deutz agrotron tractor siku $0 to $25 diecast ...   \n",
              "\n",
              "                       label  label_int  \n",
              "0     Animals & Pet Supplies          0  \n",
              "1     Animals & Pet Supplies          0  \n",
              "2     Animals & Pet Supplies          0  \n",
              "3     Animals & Pet Supplies          0  \n",
              "4     Animals & Pet Supplies          0  \n",
              "...                      ...        ...  \n",
              "5265        Vehicles & Parts         19  \n",
              "5266        Vehicles & Parts         19  \n",
              "5267        Vehicles & Parts         19  \n",
              "5268        Vehicles & Parts         19  \n",
              "5269        Vehicles & Parts         19  \n",
              "\n",
              "[5270 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9cdccd8-f5bb-4c7a-882a-4e82e2b3bb0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fidele super premium adult large breed dog foo...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>foldable pet toys linen storage cap point</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bok dok diaper pets home brand pet arabia cate...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tastybone toy chicken tastybone</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leather leash tab short dog leash mighty paw l...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>candylab moo milk van candylab 3 years candyla...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>truck modern era vehicles red white scale ho w...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>car sticker flags decal american flag sticker ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>lazer helmets bayamo pit bull full face open b...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>deutz agrotron tractor siku $0 to $25 diecast ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9cdccd8-f5bb-4c7a-882a-4e82e2b3bb0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9cdccd8-f5bb-4c7a-882a-4e82e2b3bb0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9cdccd8-f5bb-4c7a-882a-4e82e2b3bb0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### Data augmentation using BERT\n",
        "\n",
        "Here we add new sentences by paraphrasing available text to have reach number of sentences per label to a threshold"
      ],
      "metadata": {
        "id": "6-AwoPrTR85m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_number_per_label = 50  #Minimum number of sentences per label"
      ],
      "metadata": {
        "id": "JWExx_UqSJs0"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0oFFtFNCiPP",
        "outputId": "dc2d70a6-592b-4e8f-ae58-414b5cf9a75b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LasaaK80Du1k",
        "outputId": "78ac06ae-9c6b-4099-d2c8-69163ddac335"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy1shzwGDZx4",
        "outputId": "fc4a4f95-7d7b-4c14-b9f5-887150e5131f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 KB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.3.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_label = list(set(dataset['label_int'].to_list()))"
      ],
      "metadata": {
        "id": "1kb6GlB4FG6c"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.char as nac\n",
        "\n",
        "# load your dataset into a pandas dataframe\n",
        "# df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# define a function to apply data augmentation to a single text input\n",
        "def augment_text(text):\n",
        "    augmented_text = text\n",
        "    # apply random word replacement\n",
        "    aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"substitute\")\n",
        "    augmented_text = aug.augment(text)\n",
        "    # apply random character deletion\n",
        "    aug = nac.RandomCharAug(action=\"delete\")\n",
        "    augmented_text = aug.augment(augmented_text)\n",
        "    return augmented_text\n",
        "\n",
        "\n",
        "augmented_sentences=[]\n",
        "augmented_sentences_labels=[]\n",
        "\n",
        "augmented_texts = []\n",
        "\n",
        "for x in set_label:\n",
        "  tmp_data = dataset[dataset['label_int']==x].copy()\n",
        "  while(len(tmp_data)<min_number_per_label):\n",
        "    augmented_texts = []\n",
        "    for text in tmp_data['text']:\n",
        "        augmented_text = augment_text(text)\n",
        "        augmented_texts.append(augmented_text[0])\n",
        "\n",
        "    # create a new dataframe with the augmented texts and their corresponding labels\n",
        "    augmented_df = pd.DataFrame({'text': augmented_texts, 'label': tmp_data['label'], 'label_int': tmp_data['label_int']})\n",
        "\n",
        "    # concatenate the original dataframe and the augmented dataframe\n",
        "    dataset = pd.concat([dataset, augmented_df]).copy()\n",
        "\n",
        "    tmp_data = dataset[dataset['label_int']==x].copy()\n",
        "\n",
        "# train your text classification model on the augmented data\n"
      ],
      "metadata": {
        "id": "l322dBHeQJdb"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### End of data augmentation"
      ],
      "metadata": {
        "id": "duHdERmbR0m9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-5hxg-UeR55u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the names of the labels\n",
        "labels_names = list(Counter(dataset['label']).keys())\n",
        "labels_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uHdTY3p9Xfr",
        "outputId": "492a49ce-904d-42c6-ad78-14626beb4a63"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Animals & Pet Supplies',\n",
              " 'Apparel & Accessories',\n",
              " 'Arts & Entertainment',\n",
              " 'Baby & Toddler',\n",
              " 'Business & Industrial',\n",
              " 'Cameras & Optics',\n",
              " 'Electronics',\n",
              " 'Food, Beverages & Tobacco',\n",
              " 'Furniture',\n",
              " 'Hardware',\n",
              " 'Health & Beauty',\n",
              " 'Home & Garden',\n",
              " 'Luggage & Bags',\n",
              " 'Media',\n",
              " 'Office Supplies',\n",
              " 'Religious & Ceremonial',\n",
              " 'Software',\n",
              " 'Sporting Goods',\n",
              " 'Toys & Games',\n",
              " 'Vehicles & Parts']"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing each integer label and its corresponding name label\n",
        "for i, label in enumerate(labels_names):\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXCgd6QTC_k6",
        "outputId": "2e46a6fd-5ef2-4717-f74c-0850e8967f96"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to Animals & Pet Supplies\n",
            "Label 1 corresponds to Apparel & Accessories\n",
            "Label 2 corresponds to Arts & Entertainment\n",
            "Label 3 corresponds to Baby & Toddler\n",
            "Label 4 corresponds to Business & Industrial\n",
            "Label 5 corresponds to Cameras & Optics\n",
            "Label 6 corresponds to Electronics\n",
            "Label 7 corresponds to Food, Beverages & Tobacco\n",
            "Label 8 corresponds to Furniture\n",
            "Label 9 corresponds to Hardware\n",
            "Label 10 corresponds to Health & Beauty\n",
            "Label 11 corresponds to Home & Garden\n",
            "Label 12 corresponds to Luggage & Bags\n",
            "Label 13 corresponds to Media\n",
            "Label 14 corresponds to Office Supplies\n",
            "Label 15 corresponds to Religious & Ceremonial\n",
            "Label 16 corresponds to Software\n",
            "Label 17 corresponds to Sporting Goods\n",
            "Label 18 corresponds to Toys & Games\n",
            "Label 19 corresponds to Vehicles & Parts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting dataset to train, validation, and test dataframes\n",
        "train_df, test_df= train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "val_df = test_df.sample(frac=0.5)\n",
        "test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "print(f\"Number of samples in training set: {len(train_df)}\")\n",
        "print(f\"Number of samples in validation set: {len(val_df)}\")\n",
        "print(f\"Number of samples in test set: {len(test_df)}\")\n",
        "\n",
        "# extracting texts and labels from dataframes\n",
        "train_texts = train_df['text']\n",
        "train_labels = train_df['label_int']\n",
        "val_texts = val_df['text']\n",
        "val_labels = val_df['label_int']\n",
        "test_texts = test_df['text']\n",
        "test_labels = test_df['label_int']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWd2Rfp69X8g",
        "outputId": "3f9cca88-69ce-40ba-cd81-9959df0a4d91"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in training set: 4264\n",
            "Number of samples in validation set: 533\n",
            "Number of samples in test set: 533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating data generators with batch size 32\n",
        "batch_size = 32\n",
        "raw_train_batch = tf.data.Dataset.from_tensor_slices((train_texts, train_labels)).batch(batch_size)\n",
        "raw_val_batch = tf.data.Dataset.from_tensor_slices((val_texts, val_labels)).batch(batch_size)\n",
        "raw_test_batch = tf.data.Dataset.from_tensor_slices((test_texts, test_labels)).batch(batch_size)\n",
        "\n",
        "# printing texts and labels of a batch of raw train\n",
        "for text, label in raw_train_batch.take(1):\n",
        "  print('Texts: {}'.format(text))\n",
        "  print('labels: {}'.format(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4kA4X60zkC3",
        "outputId": "113eb22f-e17e-4ee3-e55c-981c17638b6a"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts: [b'toppik hair fibers black toppik hair fiber '\n",
            " b'sprayground no trespassing backpack sprayground new '\n",
            " b'believe in yourself bleach wash pullover hoodie blackcraft allsweaterhoodie as above so below clothing darkdelicious hoodie location loc 460 meta related collection outerwear meta size chart sizing chart blackcraft womens tees notbf notvip notweighed outerwear ultra wicked '\n",
            " b'beco strong starfish rough tough dog toy beco soft tough toys '\n",
            " b'dalloway john jacobs 136109 136110 360degree sku 136109 360degree sku 136110 black silver color black color gunmetal color silver computer eyeglasses dittoenable eye wear eye sale eyeglasses eyeglasses for men eyeglasses for women eyewear facebroad faceoval faceround frame type full rim frame size 138 frame type fullrim framerectangle frametypefullrim full full rim full rim eyeglasses gender men gender women gunmetal gunmetal black john jacobs large latest eyeglasses latest homepage long name alias pro titanium jj e12738 unisex eyeglasses material titanium material titanium measurement 54 18 43 145 138 men men spectacles metalworks exclusive new arrival eyeglasses price 3000 3999 pro titanium prod name dalloway product name pro titanium jj e12738 pwr rnge 8 5 quiz collection rectangle rectangle eyeglasses sale shape rectangle shape rectangle short name jj e12738 silver silver black size 54 size large spectacles styleclassic titanium unisex unisex eyeglasses women women spectacles '\n",
            " b'polichromy smooth criminal vitasei polichromy '\n",
            " b'woven rattan pendant light chandelier everything props cat. lighting cat1. overhead col. wood tone manu. 2000 2019 mat. wood styl. 2000 2019 styl1. contemporary styl2. modern subcat2. pendant subcat3. '\n",
            " b'maxi shield secret weapon mug maxi shield drag race down under maxi shield mug rupaul drag race '\n",
            " b'pink camo no stink waterproof collar wilderpup camo faire wilderpup '\n",
            " b'soporte de muro para sonos arc wmk sonos '\n",
            " b'stephanie thatcher ka hikoi putangitangi stephanie thatcher author stephanie thatcher books category maoritanga facebook feed facebook ok google type te reo maori '\n",
            " b'circle cold spring saddle circle brand circle color walnut main category saddles main category western tack riding style western saddles style trail style western subcategory saddles subcategory trail saddles trail western '\n",
            " b'neutrogena black head scrub neutrogena face wash and cleanser skin care '\n",
            " b'valere sweet dreamer valere department jewellery jewellery season winter2019 valere '\n",
            " b'baby girl scale print bathing suit trendsi '\n",
            " b'black lydia pocket backpack colette by colette hayman colour black dimensions depth 9 dimensions handledrop 7 dimensions height 28 dimensions width 23 folk dream collection hardware gunmetal no match product type backpacks '\n",
            " b'malmsey brown tan oliver sweeney badge last few colour brown maincats out of stock ygroup malm '\n",
            " b'bioworld comic iron on patch backpack bioworld allow coupons elementary school middle high school school springfever '\n",
            " b'stokke steps children growth chair stokke avg profit 200 avg profit percent 10 baby items baby items promo level 1 furniture not brandsdis not on sale not regular priced parallel price quote stokke '\n",
            " b'cover girl wig by raquel welch huw pelucas pelucascortas pelucasindetectables shortwig shortwigs wig wigs '\n",
            " b'noho bracelet watch versus versace black bracelet employee 70 gold noho quartz time20 versus versace watches watches womens size chart women '\n",
            " b'talia thong sandal maryam nassir zadeh sold out '\n",
            " b'urban color love me matte lipcolor exotic tangerine kk beauty beauty product lip colour makeup matte modicare urban color women worldshopon '\n",
            " b'sbez too small to bail sbez '\n",
            " b'the alchemist bib designer bums spo default spo disabled '\n",
            " b'ravana lankesh evil ramayana ramlila kids adults fancy dress costume without sword bookmycostume 10 12 years 12 14 years 14 16 years adult 2 3 years 3 4 years 4 5 years 5 6 years 6 7 years 7 8 years 8 10 years adult l best baby costumes for rent black black white boys fancy dress childrens fancy dress costume ideas colorful costume sale costumes for rent evil fancy dress competition for kids fancy dress ideas for fancy dress shops fancy dress themes gods mythology golden indian fancy dress kids kids fancy dress costumes male raavan costume raavana ramayan ramayan characters ramayana ramleela ramleela dussehra ramlila fancy dress ravan ravana rawan rent fancy dress rent product '\n",
            " b'stance kids captain america comic socks stance all skateboard brands socks stance '\n",
            " b'dry lite wetsuit bag creatures of leisure accessories backpacks bags bags accessories creatures of leisure spo default spo disabled surf accessories wetsuit accessories wetsuits '\n",
            " b'schwinn bicycle hub road bike front quick release nan '\n",
            " b'tusa snorkel vest children tusa hoods vests scuba '\n",
            " b'adv tent sos ground sheet lone rider adventure blackfriday2020 bmw 1200 gs bmw adventure 1200 bmw 1200 gs gs 1200 logo lone rider motorcycle motorcycle tent mototent tent '\n",
            " b'v studs diamonds havane mostafa hanafy all backpack big sale studs ']\n",
            "labels: [10 12  1  0 10  7 11 11  0  6 13 17 10  1  3 12  1 12  8  1  1  1 10  7\n",
            "  3  1  1 17 17 17 17 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting how many words are there in the whole texts of the dataset\n",
        "num_of_words = 0\n",
        "for i in dataset['text']: num_of_words += len(i.split())\n",
        "\n",
        "print(num_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QpUriFrsU_",
        "outputId": "984bfb5c-15d6-49c2-da1d-1bbffc02079a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are about 112000 words in the texts.\n",
        "\n"
      ],
      "metadata": {
        "id": "wfw3CqfZsWyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counting max sequence length and how many non-repetitive words are there in the whole texts of the dataset\n",
        "l = []\n",
        "max_seq_lenght = 0\n",
        "for i in dataset['text']:\n",
        "  lenght = len(i.split())\n",
        "  if lenght > max_seq_lenght: max_seq_lenght = lenght\n",
        "  for j in i.split():\n",
        "    if j not in l: l.append(j)\n",
        "\n",
        "print(max_seq_lenght)\n",
        "print(len(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ufQzaF9ncqZ",
        "outputId": "d7325549-12da-4f1f-f59e-8ca27d488ff6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309\n",
            "19183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum sequence length is 309 and There are about 19000 non-repetitive words in the whole dataset texts. So we set max word features to 10000 and sequence length to 350."
      ],
      "metadata": {
        "id": "cGGf8rQorkSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the text vectorization layer with 10000 words and 350 sequence length\n",
        "max_features = 10000\n",
        "sequence_length = 350\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# fitting the state of the preprocessing layer to the train set. This will cause the model to build an index of strings to integers.\n",
        "vectorize_layer.adapt(train_texts)\n",
        "\n",
        "# defining the vectorize text function\n",
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "# retrieving a sample from a batch of texts and labels from the train set\n",
        "text_batch, label_batch = next(iter(raw_train_batch))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", first_label)\n",
        "print(\"Vectorized text\", vectorize_text(first_review, first_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey2QJjO97T9P",
        "outputId": "009012c3-4291-4f93-82e7-3235edbdef1c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b'toppik hair fibers black toppik hair fiber ', shape=(), dtype=string)\n",
            "Label tf.Tensor(10, shape=(), dtype=int8)\n",
            "Vectorized text (<tf.Tensor: shape=(1, 350), dtype=int64, numpy=\n",
            "array([[5796,  141,    1,    5, 5796,  141, 1043,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int8, numpy=10>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting corresponding word of each integer \n",
        "print(\"1401 ---> \",vectorize_layer.get_vocabulary()[1401])\n",
        "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X84dkB768GSx",
        "outputId": "5601b163-e46f-4857-e4f0-88500559f515"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1401 --->  racetracks\n",
            " 313 --->  bundle\n",
            "Vocabulary size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating train, val, and test vectorized dataset and prefetching them\n",
        "train_ds = raw_train_batch.map(vectorize_text)\n",
        "val_ds = raw_val_batch.map(vectorize_text)\n",
        "test_ds = raw_test_batch.map(vectorize_text)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "DiW717GQ_77D"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "embedding_dim = 32\n",
        "num_of_labels = 20\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(num_of_labels)])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBHmGG_SAWhp",
        "outputId": "5d1c146c-a950-4fc4-de3c-28e2b32c8f6b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 32)          320032    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 32)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 32)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,692\n",
            "Trainable params: 320,692\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uL6c-YGfAwLz"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "epochs = 500\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=5,\n",
        "                                            verbose=1)\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIfmPA3SvX4d",
        "outputId": "6df77d51-5ae5-4a1f-f6b1-f3c749f859f2"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "134/134 [==============================] - 13s 95ms/step - loss: 2.8833 - accuracy: 0.1771 - val_loss: 2.7605 - val_accuracy: 0.1820\n",
            "Epoch 2/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 2.7226 - accuracy: 0.1871 - val_loss: 2.6975 - val_accuracy: 0.1820\n",
            "Epoch 3/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 2.6977 - accuracy: 0.1871 - val_loss: 2.6888 - val_accuracy: 0.1820\n",
            "Epoch 4/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6911 - accuracy: 0.1871 - val_loss: 2.6835 - val_accuracy: 0.1820\n",
            "Epoch 5/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6854 - accuracy: 0.1871 - val_loss: 2.6782 - val_accuracy: 0.1820\n",
            "Epoch 6/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6782 - accuracy: 0.1871 - val_loss: 2.6730 - val_accuracy: 0.1820\n",
            "Epoch 7/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6739 - accuracy: 0.1871 - val_loss: 2.6674 - val_accuracy: 0.1820\n",
            "Epoch 8/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6645 - accuracy: 0.1871 - val_loss: 2.6608 - val_accuracy: 0.1820\n",
            "Epoch 9/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6564 - accuracy: 0.1871 - val_loss: 2.6537 - val_accuracy: 0.1820\n",
            "Epoch 10/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6484 - accuracy: 0.1874 - val_loss: 2.6457 - val_accuracy: 0.1820\n",
            "Epoch 11/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6374 - accuracy: 0.1876 - val_loss: 2.6367 - val_accuracy: 0.1820\n",
            "Epoch 12/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6245 - accuracy: 0.1876 - val_loss: 2.6260 - val_accuracy: 0.1820\n",
            "Epoch 13/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.6116 - accuracy: 0.1881 - val_loss: 2.6153 - val_accuracy: 0.1820\n",
            "Epoch 14/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.5956 - accuracy: 0.1893 - val_loss: 2.6027 - val_accuracy: 0.1820\n",
            "Epoch 15/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.5816 - accuracy: 0.1904 - val_loss: 2.5888 - val_accuracy: 0.1820\n",
            "Epoch 16/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.5625 - accuracy: 0.1925 - val_loss: 2.5738 - val_accuracy: 0.1839\n",
            "Epoch 17/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.5427 - accuracy: 0.1986 - val_loss: 2.5571 - val_accuracy: 0.1895\n",
            "Epoch 18/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.5233 - accuracy: 0.2038 - val_loss: 2.5386 - val_accuracy: 0.1951\n",
            "Epoch 19/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.4991 - accuracy: 0.2108 - val_loss: 2.5192 - val_accuracy: 0.2008\n",
            "Epoch 20/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.4739 - accuracy: 0.2219 - val_loss: 2.4975 - val_accuracy: 0.2026\n",
            "Epoch 21/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 2.4463 - accuracy: 0.2371 - val_loss: 2.4744 - val_accuracy: 0.2101\n",
            "Epoch 22/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 2.4173 - accuracy: 0.2523 - val_loss: 2.4511 - val_accuracy: 0.2195\n",
            "Epoch 23/500\n",
            "134/134 [==============================] - 1s 7ms/step - loss: 2.3903 - accuracy: 0.2631 - val_loss: 2.4249 - val_accuracy: 0.2270\n",
            "Epoch 24/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 2.3574 - accuracy: 0.2805 - val_loss: 2.3983 - val_accuracy: 0.2458\n",
            "Epoch 25/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.3246 - accuracy: 0.2960 - val_loss: 2.3704 - val_accuracy: 0.2645\n",
            "Epoch 26/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.2906 - accuracy: 0.3112 - val_loss: 2.3413 - val_accuracy: 0.2720\n",
            "Epoch 27/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.2532 - accuracy: 0.3358 - val_loss: 2.3115 - val_accuracy: 0.2927\n",
            "Epoch 28/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.2178 - accuracy: 0.3499 - val_loss: 2.2819 - val_accuracy: 0.3114\n",
            "Epoch 29/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.1796 - accuracy: 0.3769 - val_loss: 2.2500 - val_accuracy: 0.3302\n",
            "Epoch 30/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.1396 - accuracy: 0.4029 - val_loss: 2.2176 - val_accuracy: 0.3490\n",
            "Epoch 31/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.1049 - accuracy: 0.4198 - val_loss: 2.1853 - val_accuracy: 0.3602\n",
            "Epoch 32/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.0624 - accuracy: 0.4456 - val_loss: 2.1538 - val_accuracy: 0.3771\n",
            "Epoch 33/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 2.0205 - accuracy: 0.4735 - val_loss: 2.1208 - val_accuracy: 0.3921\n",
            "Epoch 34/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.9821 - accuracy: 0.4937 - val_loss: 2.0873 - val_accuracy: 0.4203\n",
            "Epoch 35/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.9397 - accuracy: 0.5237 - val_loss: 2.0540 - val_accuracy: 0.4296\n",
            "Epoch 36/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.9018 - accuracy: 0.5352 - val_loss: 2.0217 - val_accuracy: 0.4503\n",
            "Epoch 37/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.8637 - accuracy: 0.5596 - val_loss: 1.9874 - val_accuracy: 0.4653\n",
            "Epoch 38/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.8197 - accuracy: 0.5774 - val_loss: 1.9553 - val_accuracy: 0.4972\n",
            "Epoch 39/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.7801 - accuracy: 0.5985 - val_loss: 1.9224 - val_accuracy: 0.5047\n",
            "Epoch 40/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.7394 - accuracy: 0.6243 - val_loss: 1.8901 - val_accuracy: 0.5197\n",
            "Epoch 41/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.6975 - accuracy: 0.6405 - val_loss: 1.8585 - val_accuracy: 0.5403\n",
            "Epoch 42/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.6636 - accuracy: 0.6611 - val_loss: 1.8273 - val_accuracy: 0.5478\n",
            "Epoch 43/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.6194 - accuracy: 0.6733 - val_loss: 1.7967 - val_accuracy: 0.5722\n",
            "Epoch 44/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.5837 - accuracy: 0.6801 - val_loss: 1.7639 - val_accuracy: 0.5910\n",
            "Epoch 45/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.5421 - accuracy: 0.6991 - val_loss: 1.7362 - val_accuracy: 0.6004\n",
            "Epoch 46/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.5074 - accuracy: 0.7108 - val_loss: 1.7049 - val_accuracy: 0.6285\n",
            "Epoch 47/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.4743 - accuracy: 0.7242 - val_loss: 1.6755 - val_accuracy: 0.6567\n",
            "Epoch 48/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.4389 - accuracy: 0.7362 - val_loss: 1.6487 - val_accuracy: 0.6510\n",
            "Epoch 49/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.3991 - accuracy: 0.7472 - val_loss: 1.6212 - val_accuracy: 0.6548\n",
            "Epoch 50/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.3653 - accuracy: 0.7559 - val_loss: 1.5935 - val_accuracy: 0.6642\n",
            "Epoch 51/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.3342 - accuracy: 0.7608 - val_loss: 1.5672 - val_accuracy: 0.6792\n",
            "Epoch 52/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.3042 - accuracy: 0.7735 - val_loss: 1.5401 - val_accuracy: 0.6848\n",
            "Epoch 53/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.2699 - accuracy: 0.7795 - val_loss: 1.5174 - val_accuracy: 0.6942\n",
            "Epoch 54/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.2367 - accuracy: 0.7859 - val_loss: 1.4934 - val_accuracy: 0.6923\n",
            "Epoch 55/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.2088 - accuracy: 0.7943 - val_loss: 1.4690 - val_accuracy: 0.6979\n",
            "Epoch 56/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.1810 - accuracy: 0.7985 - val_loss: 1.4460 - val_accuracy: 0.7036\n",
            "Epoch 57/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.1497 - accuracy: 0.8028 - val_loss: 1.4250 - val_accuracy: 0.7054\n",
            "Epoch 58/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.1272 - accuracy: 0.8098 - val_loss: 1.4034 - val_accuracy: 0.7092\n",
            "Epoch 59/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 1.0910 - accuracy: 0.8100 - val_loss: 1.3842 - val_accuracy: 0.7073\n",
            "Epoch 60/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.0706 - accuracy: 0.8197 - val_loss: 1.3607 - val_accuracy: 0.7167\n",
            "Epoch 61/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.0473 - accuracy: 0.8208 - val_loss: 1.3419 - val_accuracy: 0.7205\n",
            "Epoch 62/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 1.0205 - accuracy: 0.8272 - val_loss: 1.3236 - val_accuracy: 0.7242\n",
            "Epoch 63/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.9928 - accuracy: 0.8321 - val_loss: 1.3040 - val_accuracy: 0.7317\n",
            "Epoch 64/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.9726 - accuracy: 0.8361 - val_loss: 1.2867 - val_accuracy: 0.7355\n",
            "Epoch 65/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.9490 - accuracy: 0.8412 - val_loss: 1.2675 - val_accuracy: 0.7317\n",
            "Epoch 66/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.9266 - accuracy: 0.8447 - val_loss: 1.2500 - val_accuracy: 0.7392\n",
            "Epoch 67/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.9059 - accuracy: 0.8487 - val_loss: 1.2347 - val_accuracy: 0.7392\n",
            "Epoch 68/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.8865 - accuracy: 0.8511 - val_loss: 1.2199 - val_accuracy: 0.7448\n",
            "Epoch 69/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.8628 - accuracy: 0.8541 - val_loss: 1.2046 - val_accuracy: 0.7467\n",
            "Epoch 70/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.8436 - accuracy: 0.8612 - val_loss: 1.1869 - val_accuracy: 0.7542\n",
            "Epoch 71/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.8251 - accuracy: 0.8619 - val_loss: 1.1725 - val_accuracy: 0.7542\n",
            "Epoch 72/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.8052 - accuracy: 0.8635 - val_loss: 1.1603 - val_accuracy: 0.7523\n",
            "Epoch 73/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.7888 - accuracy: 0.8701 - val_loss: 1.1468 - val_accuracy: 0.7542\n",
            "Epoch 74/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.7682 - accuracy: 0.8729 - val_loss: 1.1325 - val_accuracy: 0.7542\n",
            "Epoch 75/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.7531 - accuracy: 0.8722 - val_loss: 1.1205 - val_accuracy: 0.7580\n",
            "Epoch 76/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.7379 - accuracy: 0.8743 - val_loss: 1.1087 - val_accuracy: 0.7523\n",
            "Epoch 77/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.7192 - accuracy: 0.8776 - val_loss: 1.0958 - val_accuracy: 0.7655\n",
            "Epoch 78/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.7058 - accuracy: 0.8844 - val_loss: 1.0848 - val_accuracy: 0.7617\n",
            "Epoch 79/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.8846 - val_loss: 1.0725 - val_accuracy: 0.7730\n",
            "Epoch 80/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.8841 - val_loss: 1.0628 - val_accuracy: 0.7692\n",
            "Epoch 81/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.6615 - accuracy: 0.8884 - val_loss: 1.0527 - val_accuracy: 0.7767\n",
            "Epoch 82/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.6435 - accuracy: 0.8928 - val_loss: 1.0417 - val_accuracy: 0.7805\n",
            "Epoch 83/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.6282 - accuracy: 0.8954 - val_loss: 1.0310 - val_accuracy: 0.7824\n",
            "Epoch 84/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.8985 - val_loss: 1.0217 - val_accuracy: 0.7805\n",
            "Epoch 85/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.6048 - accuracy: 0.9003 - val_loss: 1.0146 - val_accuracy: 0.7824\n",
            "Epoch 86/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5944 - accuracy: 0.9001 - val_loss: 1.0027 - val_accuracy: 0.7842\n",
            "Epoch 87/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5798 - accuracy: 0.9071 - val_loss: 0.9963 - val_accuracy: 0.7842\n",
            "Epoch 88/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5633 - accuracy: 0.9064 - val_loss: 0.9858 - val_accuracy: 0.7861\n",
            "Epoch 89/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5586 - accuracy: 0.9118 - val_loss: 0.9788 - val_accuracy: 0.7861\n",
            "Epoch 90/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5447 - accuracy: 0.9114 - val_loss: 0.9720 - val_accuracy: 0.7899\n",
            "Epoch 91/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5293 - accuracy: 0.9160 - val_loss: 0.9624 - val_accuracy: 0.7899\n",
            "Epoch 92/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5218 - accuracy: 0.9144 - val_loss: 0.9546 - val_accuracy: 0.7899\n",
            "Epoch 93/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5119 - accuracy: 0.9186 - val_loss: 0.9488 - val_accuracy: 0.7936\n",
            "Epoch 94/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.5027 - accuracy: 0.9198 - val_loss: 0.9394 - val_accuracy: 0.7917\n",
            "Epoch 95/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4879 - accuracy: 0.9268 - val_loss: 0.9352 - val_accuracy: 0.7955\n",
            "Epoch 96/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4806 - accuracy: 0.9264 - val_loss: 0.9273 - val_accuracy: 0.7936\n",
            "Epoch 97/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4701 - accuracy: 0.9301 - val_loss: 0.9194 - val_accuracy: 0.7936\n",
            "Epoch 98/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4629 - accuracy: 0.9301 - val_loss: 0.9138 - val_accuracy: 0.7955\n",
            "Epoch 99/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4495 - accuracy: 0.9332 - val_loss: 0.9089 - val_accuracy: 0.7955\n",
            "Epoch 100/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.9341 - val_loss: 0.9029 - val_accuracy: 0.7936\n",
            "Epoch 101/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.4359 - accuracy: 0.9341 - val_loss: 0.8940 - val_accuracy: 0.7936\n",
            "Epoch 102/500\n",
            "134/134 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.9369 - val_loss: 0.8923 - val_accuracy: 0.7992\n",
            "Epoch 103/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.9383 - val_loss: 0.8863 - val_accuracy: 0.8030\n",
            "Epoch 104/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4072 - accuracy: 0.9371 - val_loss: 0.8822 - val_accuracy: 0.7974\n",
            "Epoch 105/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.4003 - accuracy: 0.9409 - val_loss: 0.8791 - val_accuracy: 0.8049\n",
            "Epoch 106/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3925 - accuracy: 0.9447 - val_loss: 0.8707 - val_accuracy: 0.7974\n",
            "Epoch 107/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.9428 - val_loss: 0.8670 - val_accuracy: 0.8030\n",
            "Epoch 108/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.9477 - val_loss: 0.8627 - val_accuracy: 0.7992\n",
            "Epoch 109/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3726 - accuracy: 0.9470 - val_loss: 0.8539 - val_accuracy: 0.8049\n",
            "Epoch 110/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3605 - accuracy: 0.9456 - val_loss: 0.8527 - val_accuracy: 0.8068\n",
            "Epoch 111/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.9491 - val_loss: 0.8481 - val_accuracy: 0.8086\n",
            "Epoch 112/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3481 - accuracy: 0.9517 - val_loss: 0.8423 - val_accuracy: 0.8161\n",
            "Epoch 113/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.9524 - val_loss: 0.8409 - val_accuracy: 0.8068\n",
            "Epoch 114/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.9517 - val_loss: 0.8366 - val_accuracy: 0.8086\n",
            "Epoch 115/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.9536 - val_loss: 0.8304 - val_accuracy: 0.8124\n",
            "Epoch 116/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.9545 - val_loss: 0.8289 - val_accuracy: 0.8124\n",
            "Epoch 117/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3165 - accuracy: 0.9536 - val_loss: 0.8247 - val_accuracy: 0.8124\n",
            "Epoch 118/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3066 - accuracy: 0.9573 - val_loss: 0.8213 - val_accuracy: 0.8161\n",
            "Epoch 119/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.3054 - accuracy: 0.9547 - val_loss: 0.8153 - val_accuracy: 0.8161\n",
            "Epoch 120/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 0.3011 - accuracy: 0.9547 - val_loss: 0.8089 - val_accuracy: 0.8236\n",
            "Epoch 121/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.2908 - accuracy: 0.9604 - val_loss: 0.8092 - val_accuracy: 0.8199\n",
            "Epoch 122/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.2870 - accuracy: 0.9601 - val_loss: 0.8087 - val_accuracy: 0.8218\n",
            "Epoch 123/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.2805 - accuracy: 0.9622 - val_loss: 0.8020 - val_accuracy: 0.8180\n",
            "Epoch 124/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.9629 - val_loss: 0.8004 - val_accuracy: 0.8161\n",
            "Epoch 125/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2694 - accuracy: 0.9629 - val_loss: 0.7979 - val_accuracy: 0.8199\n",
            "Epoch 126/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2639 - accuracy: 0.9679 - val_loss: 0.7932 - val_accuracy: 0.8218\n",
            "Epoch 127/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2584 - accuracy: 0.9674 - val_loss: 0.7946 - val_accuracy: 0.8161\n",
            "Epoch 128/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2569 - accuracy: 0.9665 - val_loss: 0.7893 - val_accuracy: 0.8255\n",
            "Epoch 129/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2481 - accuracy: 0.9665 - val_loss: 0.7882 - val_accuracy: 0.8180\n",
            "Epoch 130/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2444 - accuracy: 0.9688 - val_loss: 0.7857 - val_accuracy: 0.8161\n",
            "Epoch 131/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2407 - accuracy: 0.9697 - val_loss: 0.7820 - val_accuracy: 0.8236\n",
            "Epoch 132/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2351 - accuracy: 0.9712 - val_loss: 0.7773 - val_accuracy: 0.8293\n",
            "Epoch 133/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2303 - accuracy: 0.9716 - val_loss: 0.7764 - val_accuracy: 0.8293\n",
            "Epoch 134/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2263 - accuracy: 0.9730 - val_loss: 0.7738 - val_accuracy: 0.8311\n",
            "Epoch 135/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2228 - accuracy: 0.9751 - val_loss: 0.7717 - val_accuracy: 0.8330\n",
            "Epoch 136/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2155 - accuracy: 0.9754 - val_loss: 0.7689 - val_accuracy: 0.8311\n",
            "Epoch 137/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2138 - accuracy: 0.9761 - val_loss: 0.7686 - val_accuracy: 0.8330\n",
            "Epoch 138/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9747 - val_loss: 0.7644 - val_accuracy: 0.8405\n",
            "Epoch 139/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9775 - val_loss: 0.7629 - val_accuracy: 0.8368\n",
            "Epoch 140/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.2032 - accuracy: 0.9758 - val_loss: 0.7623 - val_accuracy: 0.8368\n",
            "Epoch 141/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 0.1974 - accuracy: 0.9763 - val_loss: 0.7597 - val_accuracy: 0.8405\n",
            "Epoch 142/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.1936 - accuracy: 0.9782 - val_loss: 0.7573 - val_accuracy: 0.8405\n",
            "Epoch 143/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.1894 - accuracy: 0.9801 - val_loss: 0.7515 - val_accuracy: 0.8424\n",
            "Epoch 144/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.1884 - accuracy: 0.9791 - val_loss: 0.7522 - val_accuracy: 0.8424\n",
            "Epoch 145/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1822 - accuracy: 0.9819 - val_loss: 0.7518 - val_accuracy: 0.8424\n",
            "Epoch 146/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1823 - accuracy: 0.9803 - val_loss: 0.7491 - val_accuracy: 0.8405\n",
            "Epoch 147/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9819 - val_loss: 0.7488 - val_accuracy: 0.8405\n",
            "Epoch 148/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1722 - accuracy: 0.9829 - val_loss: 0.7471 - val_accuracy: 0.8424\n",
            "Epoch 149/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9824 - val_loss: 0.7440 - val_accuracy: 0.8462\n",
            "Epoch 150/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1682 - accuracy: 0.9833 - val_loss: 0.7419 - val_accuracy: 0.8405\n",
            "Epoch 151/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1605 - accuracy: 0.9859 - val_loss: 0.7417 - val_accuracy: 0.8443\n",
            "Epoch 152/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1588 - accuracy: 0.9833 - val_loss: 0.7393 - val_accuracy: 0.8443\n",
            "Epoch 153/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1580 - accuracy: 0.9852 - val_loss: 0.7394 - val_accuracy: 0.8405\n",
            "Epoch 154/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1543 - accuracy: 0.9855 - val_loss: 0.7360 - val_accuracy: 0.8443\n",
            "Epoch 155/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1542 - accuracy: 0.9843 - val_loss: 0.7351 - val_accuracy: 0.8424\n",
            "Epoch 156/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1477 - accuracy: 0.9862 - val_loss: 0.7382 - val_accuracy: 0.8424\n",
            "Epoch 157/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9862 - val_loss: 0.7315 - val_accuracy: 0.8424\n",
            "Epoch 158/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1424 - accuracy: 0.9871 - val_loss: 0.7323 - val_accuracy: 0.8443\n",
            "Epoch 159/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1397 - accuracy: 0.9876 - val_loss: 0.7295 - val_accuracy: 0.8443\n",
            "Epoch 160/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1409 - accuracy: 0.9883 - val_loss: 0.7300 - val_accuracy: 0.8386\n",
            "Epoch 161/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1328 - accuracy: 0.9887 - val_loss: 0.7300 - val_accuracy: 0.8424\n",
            "Epoch 162/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1336 - accuracy: 0.9871 - val_loss: 0.7232 - val_accuracy: 0.8480\n",
            "Epoch 163/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.1289 - accuracy: 0.9902 - val_loss: 0.7200 - val_accuracy: 0.8462\n",
            "Epoch 164/500\n",
            "134/134 [==============================] - 1s 6ms/step - loss: 0.1248 - accuracy: 0.9883 - val_loss: 0.7230 - val_accuracy: 0.8480\n",
            "Epoch 165/500\n",
            "134/134 [==============================] - 1s 7ms/step - loss: 0.1261 - accuracy: 0.9894 - val_loss: 0.7223 - val_accuracy: 0.8480\n",
            "Epoch 166/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 0.1239 - accuracy: 0.9885 - val_loss: 0.7262 - val_accuracy: 0.8443\n",
            "Epoch 167/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9887 - val_loss: 0.7207 - val_accuracy: 0.8462\n",
            "Epoch 168/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9894 - val_loss: 0.7169 - val_accuracy: 0.8499\n",
            "Epoch 169/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9904 - val_loss: 0.7205 - val_accuracy: 0.8499\n",
            "Epoch 170/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1137 - accuracy: 0.9904 - val_loss: 0.7175 - val_accuracy: 0.8499\n",
            "Epoch 171/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9894 - val_loss: 0.7141 - val_accuracy: 0.8462\n",
            "Epoch 172/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1116 - accuracy: 0.9913 - val_loss: 0.7153 - val_accuracy: 0.8480\n",
            "Epoch 173/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9906 - val_loss: 0.7187 - val_accuracy: 0.8518\n",
            "Epoch 174/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1046 - accuracy: 0.9927 - val_loss: 0.7193 - val_accuracy: 0.8480\n",
            "Epoch 175/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9920 - val_loss: 0.7165 - val_accuracy: 0.8386\n",
            "Epoch 176/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.1023 - accuracy: 0.9904 - val_loss: 0.7129 - val_accuracy: 0.8462\n",
            "Epoch 177/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.0998 - accuracy: 0.9937 - val_loss: 0.7163 - val_accuracy: 0.8462\n",
            "Epoch 178/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9925 - val_loss: 0.7072 - val_accuracy: 0.8462\n",
            "Epoch 179/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9930 - val_loss: 0.7167 - val_accuracy: 0.8443\n",
            "Epoch 180/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9937 - val_loss: 0.7148 - val_accuracy: 0.8480\n",
            "Epoch 181/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9937 - val_loss: 0.7138 - val_accuracy: 0.8424\n",
            "Epoch 182/500\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9934 - val_loss: 0.7102 - val_accuracy: 0.8462\n",
            "Epoch 183/500\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 0.0890 - accuracy: 0.9941 - val_loss: 0.7105 - val_accuracy: 0.8462\n",
            "Epoch 183: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing loss and accuracy of the model on the test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FksY9EwwHDkd",
        "outputId": "03523ff0-05ed-46e7-b63d-23664641d22a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.8424\n",
            "Loss:  0.7093449831008911\n",
            "Accuracy:  0.8424015045166016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the history of training and its keys\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPdyDruxHIv1",
        "outputId": "43550cfa-d0c0-437e-ff9d-cfb1e6a867f8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "metadata": {
        "id": "shbF_xRlHDqZ"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting of loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iLsoTgHGP7Oq",
        "outputId": "17edbecc-11fe-412c-8560-072771572ac6"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting of accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1uWqq-CtP-Lq",
        "outputId": "4de1b563-6de6-4ac0-be2b-664ca6c32301"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the probability model for testing\n",
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "\n",
        "# predicting test samples\n",
        "predictions = probability_model.predict(raw_test_batch.map(vectorize_text))"
      ],
      "metadata": {
        "id": "YQj61lIMvX-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# showing the first test sample result label\n",
        "np.argmax(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cbhBKR7NYPQ",
        "outputId": "bef0bf87-3b86-4ce1-ec4a-d28ee596ca16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# showing the true label of the first test sample\n",
        "test_df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNsnTWVuu3xj",
        "outputId": "a5ce8035-f6b0-44b5-95ed-8d30c222029c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         herschel sulfur spring olive night reflective ...\n",
              "label                                           Luggage & Bags\n",
              "label_int                                                   12\n",
              "Name: 3686, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bOt2UPu7NbUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** https://farrokhkarimi.github.io/"
      ],
      "metadata": {
        "id": "CSw7kwIQipyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# define a function for synonym replacement\n",
        "def synonym_replacement(text, n=1):\n",
        "    tokens = word_tokenize(text)\n",
        "    new_tokens = list(tokens)\n",
        "    random_word_list = list(set([word for word in tokens if word not in nltk.corpus.stopwords.words('english')]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = wordnet.synsets(random_word)\n",
        "        if len(synonyms) >= 1:\n",
        "            synonym = synonyms[0].lemmas()[0].name()\n",
        "            if synonym != random_word:\n",
        "                new_tokens = [synonym if token == random_word else token for token in new_tokens]\n",
        "                num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "    new_text = ' '.join(new_tokens)\n",
        "    return new_text\n",
        "\n",
        "# define a function for random insertion\n",
        "def random_insertion(text, n=1):\n",
        "    tokens = word_tokenize(text)\n",
        "    new_tokens = list(tokens)\n",
        "    for i in range(n):\n",
        "        new_word = random.choice(tokens)\n",
        "        new_tokens.insert(random.randint(0, len(new_tokens)-1), new_word)\n",
        "    new_text = ' '.join(new_tokens)\n",
        "    return new_text\n",
        "\n",
        "# # define a function for random deletion\n",
        "# def random_deletion(text, p=0.5):\n",
        "#     tokens = word_tokenize(text)\n",
        "#     new_tokens = list(tokens)\n",
        "#     for i in range(len(tokens)):\n",
        "#         if random.uniform(0, 1) < p:\n",
        "#             del new_tokens[i]\n",
        "#     new_text = ' '.join(new_tokens)\n",
        "#     return new_text\n",
        "\n",
        "# example usage of text data augmentation functions\n",
        "text = \"This is an example sentence for text data augmentation.\"\n",
        "augmented_text = synonym_replacement(text)\n",
        "print(\"Synonym replacement:\", augmented_text)\n",
        "augmented_text = random_insertion(text)\n",
        "print(\"Random insertion:\", augmented_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO_JEFtaCerG",
        "outputId": "aa4b1e13-dc91-4908-86e0-ebcd26334a43"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonym replacement: This is an example sentence for text data augmentation .\n",
            "Random insertion: This sentence is an example sentence for text data augmentation .\n"
          ]
        }
      ]
    }
  ]
}