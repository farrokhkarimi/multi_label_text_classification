{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzninvo/multi_label_text_classification/blob/main/multi_label_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label text classification\n",
        "\n",
        "**Author:** [Farrokh Karimi](https://farrokhkarimi.github.io/)  \n",
        "**Editor:** [Roham Zendehdel](https://github.com/rzninvo/)  \n",
        "**Description:** In this notebook, we want to classify the Ronash dataset into 20 categories. The original code has a accuracy of 82% and an average loss of 0.78. I'll be attempting to try different models and tune the hyperparameters to reach a better accuracy and loss. "
      ],
      "metadata": {
        "id": "Bij91pNWQOR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization\n",
        "We download the dataset and import the library requirements."
      ],
      "metadata": {
        "id": "VDDeUtDQA9Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "sL739kMAEsU9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading Data from the Google Drive link\n",
        "!gdown 1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHa9m3aLEbyP",
        "outputId": "01015d3d-440e-4faa-8a52-eba46fe74eaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy\n",
            "To: /content/Ronash_DS_Assignment.csv\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 148MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QpBuoWrC5QS",
        "outputId": "6ebbf879-6f73-4633-e59f-21489945274e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ronash_DS_Assignment.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the Ronash dataset has been succesfully downloaded."
      ],
      "metadata": {
        "id": "asOzBqCmBMpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the csv file as a dataframe\n",
        "df = pd.read_csv('Ronash_DS_Assignment.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "722bMOmzF4_H",
        "outputId": "e252c3f9-4d73-46c4-d2a0-3e355b64c927"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         product_id                                              title  \\\n",
              "0     3937721221199    Fidele Super Premium Adult Large Breed Dog Food   \n",
              "1     7353058033889                    Foldable Pet Toys Linen Storage   \n",
              "2     6594773549129                                     Bok Dok Diaper   \n",
              "3     4802008318014                              Tastybone Toy Chicken   \n",
              "4     1779705151539                Leather Leash Tab - Short Dog Leash   \n",
              "...             ...                                                ...   \n",
              "5265  4637089464407                              Candylab MOO Milk Van   \n",
              "5266  4996632444987  Truck - Modern Era Vehicles -- Red, White -  S...   \n",
              "5267  5528541003927  Car Sticker Flags Decal American Flag Sticker for   \n",
              "5268  1395163889730          Lazer Helmets Bayamo Pit Bull - Full Face   \n",
              "5269  3535679324240                             Deutz Agrotron Tractor   \n",
              "\n",
              "                 vendor                                               tags  \\\n",
              "0                Fidele  ['Adult', 'Bangalore', 'Chennai', 'Chicken', '...   \n",
              "1             Cap Point                                                 []   \n",
              "2             Pets Home  ['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...   \n",
              "3             TastyBone                                                 []   \n",
              "4            Mighty Paw                 ['Leash', 'Leash Tab', 'Training']   \n",
              "...                 ...                                                ...   \n",
              "5265           Candylab  ['3 Years +', 'candylab', 'Discount Products',...   \n",
              "5266   Woodland Scenics  ['HO Scale', 'ho-scale-items', 'vehicles', 'wo...   \n",
              "5267        Cyan Selene                                          ['Other']   \n",
              "5268  OPEN BOX BARGAINS  ['65061090', 'Antiscratch Pinlock Ready Visor'...   \n",
              "5269               Siku  ['$0 to $25', 'diecast-models', 'gift-finder',...   \n",
              "\n",
              "                    category  \n",
              "0     Animals & Pet Supplies  \n",
              "1     Animals & Pet Supplies  \n",
              "2     Animals & Pet Supplies  \n",
              "3     Animals & Pet Supplies  \n",
              "4     Animals & Pet Supplies  \n",
              "...                      ...  \n",
              "5265        Vehicles & Parts  \n",
              "5266        Vehicles & Parts  \n",
              "5267        Vehicles & Parts  \n",
              "5268        Vehicles & Parts  \n",
              "5269        Vehicles & Parts  \n",
              "\n",
              "[5270 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c48fa25-1b2b-4782-ad71-c2c400ce1eb9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>title</th>\n",
              "      <th>vendor</th>\n",
              "      <th>tags</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3937721221199</td>\n",
              "      <td>Fidele Super Premium Adult Large Breed Dog Food</td>\n",
              "      <td>Fidele</td>\n",
              "      <td>['Adult', 'Bangalore', 'Chennai', 'Chicken', '...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7353058033889</td>\n",
              "      <td>Foldable Pet Toys Linen Storage</td>\n",
              "      <td>Cap Point</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6594773549129</td>\n",
              "      <td>Bok Dok Diaper</td>\n",
              "      <td>Pets Home</td>\n",
              "      <td>['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4802008318014</td>\n",
              "      <td>Tastybone Toy Chicken</td>\n",
              "      <td>TastyBone</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1779705151539</td>\n",
              "      <td>Leather Leash Tab - Short Dog Leash</td>\n",
              "      <td>Mighty Paw</td>\n",
              "      <td>['Leash', 'Leash Tab', 'Training']</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>4637089464407</td>\n",
              "      <td>Candylab MOO Milk Van</td>\n",
              "      <td>Candylab</td>\n",
              "      <td>['3 Years +', 'candylab', 'Discount Products',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>4996632444987</td>\n",
              "      <td>Truck - Modern Era Vehicles -- Red, White -  S...</td>\n",
              "      <td>Woodland Scenics</td>\n",
              "      <td>['HO Scale', 'ho-scale-items', 'vehicles', 'wo...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>5528541003927</td>\n",
              "      <td>Car Sticker Flags Decal American Flag Sticker for</td>\n",
              "      <td>Cyan Selene</td>\n",
              "      <td>['Other']</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>1395163889730</td>\n",
              "      <td>Lazer Helmets Bayamo Pit Bull - Full Face</td>\n",
              "      <td>OPEN BOX BARGAINS</td>\n",
              "      <td>['65061090', 'Antiscratch Pinlock Ready Visor'...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>3535679324240</td>\n",
              "      <td>Deutz Agrotron Tractor</td>\n",
              "      <td>Siku</td>\n",
              "      <td>['$0 to $25', 'diecast-models', 'gift-finder',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c48fa25-1b2b-4782-ad71-c2c400ce1eb9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c48fa25-1b2b-4782-ad71-c2c400ce1eb9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c48fa25-1b2b-4782-ad71-c2c400ce1eb9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of each label\n",
        "df['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E1ZDXyPlr6y",
        "outputId": "b923f126-1092-4c61-8e19-02c757ace11d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Apparel & Accessories        1000\n",
              "Animals & Pet Supplies        500\n",
              "Food, Beverages & Tobacco     400\n",
              "Sporting Goods                400\n",
              "Luggage & Bags                400\n",
              "Home & Garden                 400\n",
              "Health & Beauty               400\n",
              "Media                         300\n",
              "Toys & Games                  300\n",
              "Furniture                     200\n",
              "Baby & Toddler                200\n",
              "Arts & Entertainment          200\n",
              "Electronics                   100\n",
              "Business & Industrial         100\n",
              "Office Supplies               100\n",
              "Vehicles & Parts              100\n",
              "Hardware                       50\n",
              "Cameras & Optics               50\n",
              "Software                       50\n",
              "Religious & Ceremonial         20\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting how many indices are duplicated in each column\n",
        "print(f\"There are {sum(df['title'].duplicated())} duplicate title.\")\n",
        "print(f\"There are {sum(df['vendor'].duplicated())} duplicate vondor.\")\n",
        "print(f\"There are {sum(df['tags'].duplicated())} duplicate tags.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_ggKoLUAEf",
        "outputId": "6e8f9a56-50b8-4c14-ea70-a13f1e81622c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 duplicate title.\n",
            "There are 1256 duplicate vondor.\n",
            "There are 716 duplicate tags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of Nan samples\n",
        "df.isnull().values.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD95efZwCRYT",
        "outputId": "4dd91fb9-403d-411b-ade4-fbc9b950fc29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are just 3 Nan samples in the dataset so we can ignore them."
      ],
      "metadata": {
        "id": "rhPJQuDEb8oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "Preprocessing is an important step in machine learning. In text classification we need to tokenize and vectozire our senteces so that our model can understand relations between the words in a sentece."
      ],
      "metadata": {
        "id": "yTGvOwQzBa7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizing and Standardizing\n",
        "Tokenize and standardizing the sentences. Also filtering the words based on a predefined regex. "
      ],
      "metadata": {
        "id": "Sw0kyrAVDDZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the function for extracting and standardizing the sentences\n",
        "def text_extraction(dfi):\n",
        "  # in this function, we concatenate text feature parts of the data as a sentence\n",
        "  sentence = ' '.join([dfi['title'], str(dfi['vendor']), dfi['tags']])\n",
        "  # Remove punctuations\n",
        "  sentence = re.sub('[^a-zA-Z0-9$.]', ' ', sentence)\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "  # Changint to lowercase\n",
        "  sentence = sentence.lower()\n",
        "  return sentence\n",
        "\n",
        "# printing 10 sample sentences\n",
        "for i in range(10):\n",
        "  print(text_extraction(df.iloc[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH9UzP7-__P2",
        "outputId": "ac5635ef-4a7e-4fa9-d488-3c6b71b9332f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fidele super premium adult large breed dog food fidele adult bangalore chennai chicken doberman dog dry foods fidele german shepherd golden retriever great dane highpriority imported labrador less than 1000 less than 2000 less than 500 mastiff orange pet nutrition \n",
            "foldable pet toys linen storage cap point \n",
            "bok dok diaper pets home brand pet arabia category pets home category small pets supplies type pet home type pet supplies \n",
            "tastybone toy chicken tastybone \n",
            "leather leash tab short dog leash mighty paw leash leash tab training \n",
            "pridebites texas guitar dog toy pride bites brand pridebites toy type plush \n",
            "burns sensitive pork potato burns 10 25 25 50 50 75 adult burns coat dog food food delivery jansale18 natural nonsale19 sensitive size 12kg size 2kg size 6kg skin \n",
            "bully sticks dog toy adog.co bully sticks dog chew toys dog toys \n",
            "kazoo tough giraffe dog toy kazoo brand kazoo june2021 kazoo material plush plush \n",
            "orgo dog biscuits fresh milk petku brand orgo category dogs dogs lifestage all lifestages orgo price rp 0 to rp 100.000 subcategory treats treats \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the dataset\n",
        "dataset = pd.DataFrame(columns=['text', 'label'])\n",
        "for i in range(len(df)):\n",
        "  dataset = dataset.append({'text':text_extraction(df.iloc[i]), 'label':df.iloc[i]['category']}, ignore_index = True)\n",
        "\n",
        "# creating integer labels for multiclass training\n",
        "dataset['label_int'] = pd.Categorical(dataset['label']).codes\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7x4WG7NC9Xz3",
        "outputId": "8ccafacb-012f-47fb-ec0d-af74af2923d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0     fidele super premium adult large breed dog foo...   \n",
              "1            foldable pet toys linen storage cap point    \n",
              "2     bok dok diaper pets home brand pet arabia cate...   \n",
              "3                      tastybone toy chicken tastybone    \n",
              "4     leather leash tab short dog leash mighty paw l...   \n",
              "...                                                 ...   \n",
              "5265  candylab moo milk van candylab 3 years candyla...   \n",
              "5266  truck modern era vehicles red white scale ho w...   \n",
              "5267  car sticker flags decal american flag sticker ...   \n",
              "5268  lazer helmets bayamo pit bull full face open b...   \n",
              "5269  deutz agrotron tractor siku $0 to $25 diecast ...   \n",
              "\n",
              "                       label  label_int  \n",
              "0     Animals & Pet Supplies          0  \n",
              "1     Animals & Pet Supplies          0  \n",
              "2     Animals & Pet Supplies          0  \n",
              "3     Animals & Pet Supplies          0  \n",
              "4     Animals & Pet Supplies          0  \n",
              "...                      ...        ...  \n",
              "5265        Vehicles & Parts         19  \n",
              "5266        Vehicles & Parts         19  \n",
              "5267        Vehicles & Parts         19  \n",
              "5268        Vehicles & Parts         19  \n",
              "5269        Vehicles & Parts         19  \n",
              "\n",
              "[5270 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d98c7a09-0a40-406d-bd0b-0172b98edf24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fidele super premium adult large breed dog foo...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>foldable pet toys linen storage cap point</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bok dok diaper pets home brand pet arabia cate...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tastybone toy chicken tastybone</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leather leash tab short dog leash mighty paw l...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>candylab moo milk van candylab 3 years candyla...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>truck modern era vehicles red white scale ho w...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>car sticker flags decal american flag sticker ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>lazer helmets bayamo pit bull full face open b...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>deutz agrotron tractor siku $0 to $25 diecast ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d98c7a09-0a40-406d-bd0b-0172b98edf24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d98c7a09-0a40-406d-bd0b-0172b98edf24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d98c7a09-0a40-406d-bd0b-0172b98edf24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the names of the labels\n",
        "labels_names = list(Counter(dataset['label']).keys())\n",
        "labels_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uHdTY3p9Xfr",
        "outputId": "abe9afa7-9d68-4d8d-c589-9ee919f2ef5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Animals & Pet Supplies',\n",
              " 'Apparel & Accessories',\n",
              " 'Arts & Entertainment',\n",
              " 'Baby & Toddler',\n",
              " 'Business & Industrial',\n",
              " 'Cameras & Optics',\n",
              " 'Electronics',\n",
              " 'Food, Beverages & Tobacco',\n",
              " 'Furniture',\n",
              " 'Hardware',\n",
              " 'Health & Beauty',\n",
              " 'Home & Garden',\n",
              " 'Luggage & Bags',\n",
              " 'Media',\n",
              " 'Office Supplies',\n",
              " 'Religious & Ceremonial',\n",
              " 'Software',\n",
              " 'Sporting Goods',\n",
              " 'Toys & Games',\n",
              " 'Vehicles & Parts']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing each integer label and its corresponding name label\n",
        "for i, label in enumerate(labels_names):\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXCgd6QTC_k6",
        "outputId": "50f449ae-8257-4d3d-94be-0bf9380eebe2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to Animals & Pet Supplies\n",
            "Label 1 corresponds to Apparel & Accessories\n",
            "Label 2 corresponds to Arts & Entertainment\n",
            "Label 3 corresponds to Baby & Toddler\n",
            "Label 4 corresponds to Business & Industrial\n",
            "Label 5 corresponds to Cameras & Optics\n",
            "Label 6 corresponds to Electronics\n",
            "Label 7 corresponds to Food, Beverages & Tobacco\n",
            "Label 8 corresponds to Furniture\n",
            "Label 9 corresponds to Hardware\n",
            "Label 10 corresponds to Health & Beauty\n",
            "Label 11 corresponds to Home & Garden\n",
            "Label 12 corresponds to Luggage & Bags\n",
            "Label 13 corresponds to Media\n",
            "Label 14 corresponds to Office Supplies\n",
            "Label 15 corresponds to Religious & Ceremonial\n",
            "Label 16 corresponds to Software\n",
            "Label 17 corresponds to Sporting Goods\n",
            "Label 18 corresponds to Toys & Games\n",
            "Label 19 corresponds to Vehicles & Parts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data sampling\n",
        "After standardizing the dataset, It's time to **split** the dataset into train dataset and test datasets. The selected ratio of data is 80% of the dataset for training and 20% of the dataset is for testing and validation. 50% of the testing dataset is for validation and the rest is for testing our model."
      ],
      "metadata": {
        "id": "jQMCY52NB6MP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting dataset to train, validation, and test dataframes\n",
        "train_df, test_df= train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "val_df = test_df.sample(frac=0.5)\n",
        "test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "print(f\"Number of samples in training set: {len(train_df)}\")\n",
        "print(f\"Number of samples in validation set: {len(val_df)}\")\n",
        "print(f\"Number of samples in test set: {len(test_df)}\")\n",
        "\n",
        "# extracting texts and labels from dataframes\n",
        "train_texts = train_df['text']\n",
        "train_labels = train_df['label_int']\n",
        "val_texts = val_df['text']\n",
        "val_labels = val_df['label_int']\n",
        "test_texts = test_df['text']\n",
        "test_labels = test_df['label_int']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWd2Rfp69X8g",
        "outputId": "6c193536-5266-4b9a-cdad-408e4de1cc9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in training set: 4216\n",
            "Number of samples in validation set: 527\n",
            "Number of samples in test set: 527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batching\n",
        "We need to split our datasets into 32 sized batches."
      ],
      "metadata": {
        "id": "jxBSPdbkCfJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating data generators with batch size 32\n",
        "batch_size = 32\n",
        "raw_train_batch = tf.data.Dataset.from_tensor_slices((train_texts, train_labels)).batch(batch_size)\n",
        "raw_val_batch = tf.data.Dataset.from_tensor_slices((val_texts, val_labels)).batch(batch_size)\n",
        "raw_test_batch = tf.data.Dataset.from_tensor_slices((test_texts, test_labels)).batch(batch_size)\n",
        "\n",
        "# printing texts and labels of a batch of raw train\n",
        "for text, label in raw_train_batch.take(1):\n",
        "  print('Texts: {}'.format(text))\n",
        "  print('labels: {}'.format(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4kA4X60zkC3",
        "outputId": "2a016279-7bae-408e-d6fa-fd094c37bb5e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts: [b'housie tambola game by brands with foldable reusable tickets snooplay 13 17 year olds 18 years above 251 500 8 12 year olds age no bar all time favourite below 1000 below 400 below 500 best selling board games creative games gifts customer favourites diwali family friends night family games friends family nights geek gifts for boys gifts for friends gifts for girls gifts for kids gifts for parents googleshopping nerd or geek new new collection outdoor games party accessories party essentials party freak party games party games for grown ups party games for kids premium unique new toys '\n",
            " b'foldable waterproof raised dog bed dogiti '\n",
            " b'quadrello di bufala cheese cut wrapped by igourmet category cheese cut cheeses milk type buffalo nutrition full set origin italy shipping perishable texture semi soft type stinky and washed rind wholesale cheese collection '\n",
            " b'quay vip pink navy to pink lens quay accessories new summer sunglasses '\n",
            " b'seachem multitest ammonia seachem '\n",
            " b'smart electric cat teasing toy pet clever cat toys cats rr track catproducts rr track cattoys '\n",
            " b'petroleum mixture sign the sign shed black text chemical chemical signs flammable signs general hazard portrait yellow bg '\n",
            " b'scott kingery andrew mccutchen philadelphia phillies ring the bell dual bobblehead foco data athlete andrew mccutchen data athlete scott kingery data city philadelphia data edition exclusive data filter collection no data filter discount yes data league mlb data region pennsylvania data sub category1 bobbleheads data team philadelphia phillies '\n",
            " b'diy personalised dreamcatcher activity kit sea animal doxbox store '\n",
            " b'dainty corduroy bow in lilac sweet first love bow corduroy headband purple spo disabled wos '\n",
            " b'new bts stylish backpack the pocket store '\n",
            " b'planet bike big buck fat front planet bike bicycle fenders bike accessories bikes fenders front fenders full price planet bike unisex '\n",
            " b'ms. better trans canada bitters enterprises jesemi inc. betters canada ms trans '\n",
            " b'drawstring backpack pink zig zag yoobi 10 15 2020 primedaydeal accessories all bags flair back to school backpacks bags bf2019 book bag book bags bookbag bookbags newyear pink pink zig zag sale summer2020 supplybundle zig zags '\n",
            " b'pineapple mini food speaker magnum brands add on birthday gift girl music pos speaker '\n",
            " b'interactive iq treat ball toy for dogs cats cj feeder waterer pet supplies '\n",
            " b'whisper of lord ganesha tarot deck u.s. games '\n",
            " b'handcrafted aasha cuff bracelet colorful cuff bracelet made with wooden beads wrapped with recycled sari fabrics. aasha bracelet comfy fair trade handcrafted handmade jewelry '\n",
            " b'idrop belik facial anti aging wrinkle ultrasonic face massager toothbrush attachment idrop anti aging anti wrinkle electric massager face massage facial massager health health beauty health fitness health care healthcare healthy healthy massager massage massager new ultrasonic '\n",
            " b'wood nativity puzzle mud pie one coas 10760023 baby children christmas gift god jesus kid religion toy '\n",
            " b'p.l.a.y. zoomierex fantastug sea foam dog toy p.l.a.y. brand p.l.a.y. summer collection toy type fetch toy type floating toy type rubber toy type tug twr '\n",
            " b'wallis simpson signed autobiography paul fraser collectibles autographs '\n",
            " b'imperial earring daya jewelry brass flower gold imperial spo default spo disabled spo enabled star tribal '\n",
            " b'armadillo nest charcoal armadillo alfresco armadillo door mats down to earth floor homeware homeware rugs mats labour weekend living modern boho rug rugs mats '\n",
            " b'millie pillow foreside pillows textiles '\n",
            " b'jelly brush aprilskin.us all '\n",
            " b'alarm you re little bitch blue blue blue crew cute exclude feed agegroup adult feed cl0 regularprice womens sassy funny words inappropriate cute profanity swear words exclude rude crude feed color blue feed cond new feed gender feed gender female feed gpc 209 funny inappropriate print profanity red regularprice rude crude sassy socks swear words womens words '\n",
            " b'boutique de paris lashes4today glamorous lashes luxury '\n",
            " b'dog pakiet dnp pc skin support pick me pets brand dolina noteci category pet supplies type dog food '\n",
            " b'plaza weekend diaper bag 7am label final sale addswatchrow adult age adult category diaper bags category weekenders color black color grey diaper diaper diaper ba dipper style plaza bag voyage '\n",
            " b'water sterling silver necklace wear the peace 925 sterling silver all products necklaces new arrivals '\n",
            " b'bain ultra violet rastase adha2020 adjusted assaad back in stock items bahaa black friday 2020 enabled blond absolu blondabsolu ramadan21 btpcat main 132768825422 btpcat other 132768825422 elian dada fadia el mendelek for colored blond hair hair care haircare summerfiesta sale jan 4 2021 price increase july 28th updated july increase ker aprist1st 2021 increase ker august 2021 price increase ker march 1st 2021 price increase ker priceincrease june1st 2021 kerastase ramadan21 rastase loolia2y mahmoud al zarif michel zeytoun non solar october 1st 2020 price increase or or reviews ppd price decrease 16th september 2021 ppd price decrease sept 2021 ppd price increase october1st 2021 ppd pricedecrease midseptember2021 ppd priceincrease 12th october 2021 price updated shampoos shant tawetian shop all stockcount 31 03 2021 weekend summerfiesta sale ']\n",
            "labels: [18  0  7  1  0  0  4  2  0  1 12 17  7 12 18  0 15  1 10 18  0  2  1 11\n",
            "  2  9  1 10  0 12  1 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting how many words are there in the whole texts of the dataset\n",
        "num_of_words = 0\n",
        "for i in dataset['text']: num_of_words += len(i.split())\n",
        "\n",
        "print(num_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QpUriFrsU_",
        "outputId": "ab066a8f-8d2d-4d6c-f6e8-28166b4e6415"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are about 112000 words in the texts.\n",
        "\n"
      ],
      "metadata": {
        "id": "wfw3CqfZsWyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counting max sequence length and how many non-repetitive words are there in the whole texts of the dataset\n",
        "l = []\n",
        "max_seq_length = 0\n",
        "for i in dataset['text']:\n",
        "  length = len(i.split())\n",
        "  if length > max_seq_length: max_seq_length = length\n",
        "  for j in i.split():\n",
        "    if j not in l: l.append(j)\n",
        "\n",
        "print(max_seq_length)\n",
        "print(len(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ufQzaF9ncqZ",
        "outputId": "86d648c5-d564-4422-9d28-b7ab0d70aadd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309\n",
            "18933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum sequence length is 309 and There are about 19000 non-repetitive words in the whole dataset texts. So we set max word features to 10000 and sequence length to 350. \n",
        "    \n",
        "**Edits:** Original code had set the maximum features to 10000. I'll be using the entire features with a maximum length of 310"
      ],
      "metadata": {
        "id": "cGGf8rQorkSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing the datasets\n",
        "Each sentece has a word vector with a length of 350. Each unique word is mapped to a number between 0 and 10000"
      ],
      "metadata": {
        "id": "pom3gtdCD1wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the text vectorization layer with 20000 words and 350 sequence length\n",
        "max_features = 10000\n",
        "sequence_length = 350\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# fitting the state of the preprocessing layer to the train set. This will cause the model to build an index of strings to integers.\n",
        "vectorize_layer.adapt(train_texts)\n",
        "\n",
        "# defining the vectorize text function\n",
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "# retrieving a sample from a batch of texts and labels from the train set\n",
        "text_batch, label_batch = next(iter(raw_train_batch))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", first_label)\n",
        "print(\"Vectorized text\", vectorize_text(first_review, first_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey2QJjO97T9P",
        "outputId": "801b3dbb-216f-479b-e6f5-6797951f73bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b'housie tambola game by brands with foldable reusable tickets snooplay 13 17 year olds 18 years above 251 500 8 12 year olds age no bar all time favourite below 1000 below 400 below 500 best selling board games creative games gifts customer favourites diwali family friends night family games friends family nights geek gifts for boys gifts for friends gifts for girls gifts for kids gifts for parents googleshopping nerd or geek new new collection outdoor games party accessories party essentials party freak party games party games for grown ups party games for kids premium unique new toys ', shape=(), dtype=string)\n",
            "Label tf.Tensor(18, shape=(), dtype=int8)\n",
            "Vectorized text (<tf.Tensor: shape=(1, 350), dtype=int64, numpy=\n",
            "array([[   1, 9229,  192,   23,  343,   51, 1546, 2392, 9089, 9635,  740,\n",
            "        1609,  275, 2882,  372,   69,  959,    1,  134,  109,   89,  275,\n",
            "        2882,   35,   55,  381,   16,  480, 7346,  783,  181,  783,  961,\n",
            "         783,  134,   79, 2792,  104,   57, 1195,   57,   53, 3072,    1,\n",
            "        5047,  237, 1078,  716,  237,   57, 1078,  237, 6529, 4896,   53,\n",
            "          13,  334,   53,   13, 1078,   53,   13,  179,   53,   13,   62,\n",
            "          53,   13, 3473,    1,    1,  303, 4896,    3,    3,    8,  157,\n",
            "          57,  250,   17,  250,  316,  250, 7261,  250,   57,  250,   57,\n",
            "          13, 1904, 5674,  250,   57,   13,   62,  360,  632,    3,    6,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int8, numpy=18>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting corresponding word of each integer \n",
        "print(\"1401 ---> \",vectorize_layer.get_vocabulary()[1401])\n",
        "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X84dkB768GSx",
        "outputId": "3e29eb55-9d8e-472e-9145-f94bf863f4b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1401 --->  heel\n",
            " 313 --->  is\n",
            "Vocabulary size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating train, val, and test vectorized dataset and prefetching them\n",
        "train_ds = raw_train_batch.map(vectorize_text)\n",
        "val_ds = raw_val_batch.map(vectorize_text)\n",
        "test_ds = raw_test_batch.map(vectorize_text)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "DiW717GQ_77D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the Model\n",
        "In this section we'll build our text classifier model."
      ],
      "metadata": {
        "id": "S_kOCHQWEBc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "embedding_dim = 32\n",
        "num_of_labels = 20\n",
        "vocab_size = len(vectorize_layer.get_vocabulary())\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(vocab_size + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(num_of_labels)])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBHmGG_SAWhp",
        "outputId": "85721f80-0844-4161-ce58-0b8ba99da568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 32)          320032    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 32)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 32)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,692\n",
            "Trainable params: 320,692\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uL6c-YGfAwLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "epochs = 500\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=5,\n",
        "                                            verbose=1)\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIfmPA3SvX4d",
        "outputId": "1595829a-edc9-49ea-ef0f-bfe9538a0cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "132/132 [==============================] - 3s 16ms/step - loss: 2.8733 - accuracy: 0.1800 - val_loss: 2.7578 - val_accuracy: 0.1898\n",
            "Epoch 2/500\n",
            "132/132 [==============================] - 3s 21ms/step - loss: 2.7064 - accuracy: 0.1881 - val_loss: 2.6873 - val_accuracy: 0.1898\n",
            "Epoch 3/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 2.6782 - accuracy: 0.1881 - val_loss: 2.6749 - val_accuracy: 0.1898\n",
            "Epoch 4/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.6673 - accuracy: 0.1881 - val_loss: 2.6678 - val_accuracy: 0.1898\n",
            "Epoch 5/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 2.6618 - accuracy: 0.1881 - val_loss: 2.6608 - val_accuracy: 0.1898\n",
            "Epoch 6/500\n",
            "132/132 [==============================] - 4s 31ms/step - loss: 2.6561 - accuracy: 0.1881 - val_loss: 2.6540 - val_accuracy: 0.1898\n",
            "Epoch 7/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 2.6481 - accuracy: 0.1883 - val_loss: 2.6460 - val_accuracy: 0.1898\n",
            "Epoch 8/500\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 2.6388 - accuracy: 0.1883 - val_loss: 2.6371 - val_accuracy: 0.1898\n",
            "Epoch 9/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 2.6286 - accuracy: 0.1886 - val_loss: 2.6268 - val_accuracy: 0.1917\n",
            "Epoch 10/500\n",
            "132/132 [==============================] - 3s 22ms/step - loss: 2.6159 - accuracy: 0.1886 - val_loss: 2.6156 - val_accuracy: 0.1917\n",
            "Epoch 11/500\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 2.6036 - accuracy: 0.1898 - val_loss: 2.6037 - val_accuracy: 0.1917\n",
            "Epoch 12/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.5902 - accuracy: 0.1909 - val_loss: 2.5899 - val_accuracy: 0.1917\n",
            "Epoch 13/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 2.5736 - accuracy: 0.1945 - val_loss: 2.5755 - val_accuracy: 0.1935\n",
            "Epoch 14/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 2.5544 - accuracy: 0.2004 - val_loss: 2.5605 - val_accuracy: 0.1973\n",
            "Epoch 15/500\n",
            "132/132 [==============================] - 3s 22ms/step - loss: 2.5344 - accuracy: 0.2071 - val_loss: 2.5440 - val_accuracy: 0.2030\n",
            "Epoch 16/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.5129 - accuracy: 0.2142 - val_loss: 2.5260 - val_accuracy: 0.2087\n",
            "Epoch 17/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 2.4944 - accuracy: 0.2189 - val_loss: 2.5078 - val_accuracy: 0.2182\n",
            "Epoch 18/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.4683 - accuracy: 0.2272 - val_loss: 2.4884 - val_accuracy: 0.2220\n",
            "Epoch 19/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 2.4447 - accuracy: 0.2358 - val_loss: 2.4680 - val_accuracy: 0.2277\n",
            "Epoch 20/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 2.4208 - accuracy: 0.2457 - val_loss: 2.4460 - val_accuracy: 0.2429\n",
            "Epoch 21/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 2.3969 - accuracy: 0.2562 - val_loss: 2.4230 - val_accuracy: 0.2600\n",
            "Epoch 22/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.3652 - accuracy: 0.2671 - val_loss: 2.3997 - val_accuracy: 0.2694\n",
            "Epoch 23/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.3368 - accuracy: 0.2825 - val_loss: 2.3749 - val_accuracy: 0.2713\n",
            "Epoch 24/500\n",
            "132/132 [==============================] - 3s 21ms/step - loss: 2.3039 - accuracy: 0.2920 - val_loss: 2.3487 - val_accuracy: 0.2732\n",
            "Epoch 25/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 2.2703 - accuracy: 0.3126 - val_loss: 2.3235 - val_accuracy: 0.2827\n",
            "Epoch 26/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.2391 - accuracy: 0.3254 - val_loss: 2.2965 - val_accuracy: 0.2922\n",
            "Epoch 27/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.2055 - accuracy: 0.3427 - val_loss: 2.2687 - val_accuracy: 0.3074\n",
            "Epoch 28/500\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 2.1674 - accuracy: 0.3684 - val_loss: 2.2406 - val_accuracy: 0.3264\n",
            "Epoch 29/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 2.1371 - accuracy: 0.3895 - val_loss: 2.2117 - val_accuracy: 0.3435\n",
            "Epoch 30/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.0932 - accuracy: 0.4158 - val_loss: 2.1829 - val_accuracy: 0.3567\n",
            "Epoch 31/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 2.0592 - accuracy: 0.4336 - val_loss: 2.1525 - val_accuracy: 0.3776\n",
            "Epoch 32/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 2.0240 - accuracy: 0.4561 - val_loss: 2.1237 - val_accuracy: 0.4004\n",
            "Epoch 33/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.9879 - accuracy: 0.4768 - val_loss: 2.0937 - val_accuracy: 0.4118\n",
            "Epoch 34/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 1.9455 - accuracy: 0.4983 - val_loss: 2.0643 - val_accuracy: 0.4250\n",
            "Epoch 35/500\n",
            "132/132 [==============================] - 3s 23ms/step - loss: 1.9060 - accuracy: 0.5173 - val_loss: 2.0351 - val_accuracy: 0.4478\n",
            "Epoch 36/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 1.8760 - accuracy: 0.5429 - val_loss: 2.0059 - val_accuracy: 0.4554\n",
            "Epoch 37/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.8283 - accuracy: 0.5595 - val_loss: 1.9778 - val_accuracy: 0.4744\n",
            "Epoch 38/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.7939 - accuracy: 0.5821 - val_loss: 1.9483 - val_accuracy: 0.4972\n",
            "Epoch 39/500\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 1.7553 - accuracy: 0.5965 - val_loss: 1.9183 - val_accuracy: 0.5085\n",
            "Epoch 40/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 1.7162 - accuracy: 0.6195 - val_loss: 1.8900 - val_accuracy: 0.5199\n",
            "Epoch 41/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 1.6783 - accuracy: 0.6416 - val_loss: 1.8633 - val_accuracy: 0.5465\n",
            "Epoch 42/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.6437 - accuracy: 0.6516 - val_loss: 1.8348 - val_accuracy: 0.5617\n",
            "Epoch 43/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.5997 - accuracy: 0.6727 - val_loss: 1.8067 - val_accuracy: 0.5655\n",
            "Epoch 44/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.5648 - accuracy: 0.6895 - val_loss: 1.7795 - val_accuracy: 0.5825\n",
            "Epoch 45/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 1.5300 - accuracy: 0.6954 - val_loss: 1.7541 - val_accuracy: 0.5863\n",
            "Epoch 46/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.4917 - accuracy: 0.7149 - val_loss: 1.7280 - val_accuracy: 0.5996\n",
            "Epoch 47/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.4592 - accuracy: 0.7234 - val_loss: 1.7043 - val_accuracy: 0.6091\n",
            "Epoch 48/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.4242 - accuracy: 0.7320 - val_loss: 1.6791 - val_accuracy: 0.6148\n",
            "Epoch 49/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.3854 - accuracy: 0.7472 - val_loss: 1.6551 - val_accuracy: 0.6167\n",
            "Epoch 50/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.3550 - accuracy: 0.7588 - val_loss: 1.6293 - val_accuracy: 0.6262\n",
            "Epoch 51/500\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 1.3270 - accuracy: 0.7609 - val_loss: 1.6068 - val_accuracy: 0.6376\n",
            "Epoch 52/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.2951 - accuracy: 0.7676 - val_loss: 1.5881 - val_accuracy: 0.6357\n",
            "Epoch 53/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.2617 - accuracy: 0.7770 - val_loss: 1.5668 - val_accuracy: 0.6414\n",
            "Epoch 54/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.2319 - accuracy: 0.7908 - val_loss: 1.5438 - val_accuracy: 0.6509\n",
            "Epoch 55/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.1967 - accuracy: 0.7936 - val_loss: 1.5235 - val_accuracy: 0.6603\n",
            "Epoch 56/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.1717 - accuracy: 0.8003 - val_loss: 1.5042 - val_accuracy: 0.6679\n",
            "Epoch 57/500\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 1.1436 - accuracy: 0.8060 - val_loss: 1.4842 - val_accuracy: 0.6717\n",
            "Epoch 58/500\n",
            "132/132 [==============================] - 4s 30ms/step - loss: 1.1140 - accuracy: 0.8112 - val_loss: 1.4688 - val_accuracy: 0.6774\n",
            "Epoch 59/500\n",
            "132/132 [==============================] - 3s 24ms/step - loss: 1.0869 - accuracy: 0.8148 - val_loss: 1.4497 - val_accuracy: 0.6793\n",
            "Epoch 60/500\n",
            "132/132 [==============================] - 3s 22ms/step - loss: 1.0613 - accuracy: 0.8207 - val_loss: 1.4329 - val_accuracy: 0.6850\n",
            "Epoch 61/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.0404 - accuracy: 0.8254 - val_loss: 1.4160 - val_accuracy: 0.6850\n",
            "Epoch 62/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.0157 - accuracy: 0.8314 - val_loss: 1.3996 - val_accuracy: 0.6869\n",
            "Epoch 63/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.9924 - accuracy: 0.8378 - val_loss: 1.3855 - val_accuracy: 0.6812\n",
            "Epoch 64/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.9656 - accuracy: 0.8394 - val_loss: 1.3706 - val_accuracy: 0.6945\n",
            "Epoch 65/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.9449 - accuracy: 0.8430 - val_loss: 1.3541 - val_accuracy: 0.7002\n",
            "Epoch 66/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.9201 - accuracy: 0.8487 - val_loss: 1.3413 - val_accuracy: 0.6983\n",
            "Epoch 67/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.8981 - accuracy: 0.8548 - val_loss: 1.3264 - val_accuracy: 0.7059\n",
            "Epoch 68/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.8753 - accuracy: 0.8560 - val_loss: 1.3133 - val_accuracy: 0.7097\n",
            "Epoch 69/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.8566 - accuracy: 0.8532 - val_loss: 1.2996 - val_accuracy: 0.7116\n",
            "Epoch 70/500\n",
            "132/132 [==============================] - 3s 26ms/step - loss: 0.8376 - accuracy: 0.8615 - val_loss: 1.2895 - val_accuracy: 0.7135\n",
            "Epoch 71/500\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 0.8158 - accuracy: 0.8669 - val_loss: 1.2770 - val_accuracy: 0.7192\n",
            "Epoch 72/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.8014 - accuracy: 0.8691 - val_loss: 1.2666 - val_accuracy: 0.7173\n",
            "Epoch 73/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7828 - accuracy: 0.8698 - val_loss: 1.2533 - val_accuracy: 0.7230\n",
            "Epoch 74/500\n",
            "132/132 [==============================] - 3s 21ms/step - loss: 0.7642 - accuracy: 0.8733 - val_loss: 1.2436 - val_accuracy: 0.7287\n",
            "Epoch 75/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7459 - accuracy: 0.8774 - val_loss: 1.2324 - val_accuracy: 0.7324\n",
            "Epoch 76/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.7258 - accuracy: 0.8800 - val_loss: 1.2220 - val_accuracy: 0.7362\n",
            "Epoch 77/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.7132 - accuracy: 0.8843 - val_loss: 1.2137 - val_accuracy: 0.7362\n",
            "Epoch 78/500\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.6945 - accuracy: 0.8859 - val_loss: 1.2055 - val_accuracy: 0.7343\n",
            "Epoch 79/500\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.6829 - accuracy: 0.8888 - val_loss: 1.1947 - val_accuracy: 0.7381\n",
            "Epoch 80/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.6649 - accuracy: 0.8914 - val_loss: 1.1864 - val_accuracy: 0.7381\n",
            "Epoch 81/500\n",
            "132/132 [==============================] - 3s 24ms/step - loss: 0.6511 - accuracy: 0.8933 - val_loss: 1.1770 - val_accuracy: 0.7438\n",
            "Epoch 82/500\n",
            "132/132 [==============================] - 3s 22ms/step - loss: 0.6375 - accuracy: 0.8999 - val_loss: 1.1697 - val_accuracy: 0.7419\n",
            "Epoch 83/500\n",
            "132/132 [==============================] - 3s 22ms/step - loss: 0.6243 - accuracy: 0.9001 - val_loss: 1.1628 - val_accuracy: 0.7400\n",
            "Epoch 84/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.6102 - accuracy: 0.9042 - val_loss: 1.1561 - val_accuracy: 0.7457\n",
            "Epoch 85/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.5976 - accuracy: 0.9058 - val_loss: 1.1496 - val_accuracy: 0.7438\n",
            "Epoch 86/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.5818 - accuracy: 0.9058 - val_loss: 1.1399 - val_accuracy: 0.7457\n",
            "Epoch 87/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.5686 - accuracy: 0.9087 - val_loss: 1.1352 - val_accuracy: 0.7457\n",
            "Epoch 88/500\n",
            "132/132 [==============================] - 4s 30ms/step - loss: 0.5598 - accuracy: 0.9118 - val_loss: 1.1293 - val_accuracy: 0.7457\n",
            "Epoch 89/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.5493 - accuracy: 0.9139 - val_loss: 1.1202 - val_accuracy: 0.7476\n",
            "Epoch 90/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.5360 - accuracy: 0.9151 - val_loss: 1.1180 - val_accuracy: 0.7457\n",
            "Epoch 91/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.5223 - accuracy: 0.9158 - val_loss: 1.1111 - val_accuracy: 0.7457\n",
            "Epoch 92/500\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 0.5124 - accuracy: 0.9227 - val_loss: 1.1057 - val_accuracy: 0.7495\n",
            "Epoch 93/500\n",
            "132/132 [==============================] - 3s 23ms/step - loss: 0.5055 - accuracy: 0.9231 - val_loss: 1.0979 - val_accuracy: 0.7495\n",
            "Epoch 94/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.4929 - accuracy: 0.9260 - val_loss: 1.0946 - val_accuracy: 0.7495\n",
            "Epoch 95/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.4819 - accuracy: 0.9267 - val_loss: 1.0871 - val_accuracy: 0.7495\n",
            "Epoch 96/500\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.4714 - accuracy: 0.9260 - val_loss: 1.0838 - val_accuracy: 0.7495\n",
            "Epoch 97/500\n",
            "132/132 [==============================] - 3s 24ms/step - loss: 0.4628 - accuracy: 0.9315 - val_loss: 1.0752 - val_accuracy: 0.7514\n",
            "Epoch 98/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.4549 - accuracy: 0.9326 - val_loss: 1.0724 - val_accuracy: 0.7495\n",
            "Epoch 99/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.4441 - accuracy: 0.9345 - val_loss: 1.0692 - val_accuracy: 0.7533\n",
            "Epoch 100/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4315 - accuracy: 0.9350 - val_loss: 1.0660 - val_accuracy: 0.7514\n",
            "Epoch 101/500\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.4266 - accuracy: 0.9348 - val_loss: 1.0586 - val_accuracy: 0.7571\n",
            "Epoch 102/500\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 0.4145 - accuracy: 0.9395 - val_loss: 1.0581 - val_accuracy: 0.7552\n",
            "Epoch 103/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.4113 - accuracy: 0.9371 - val_loss: 1.0560 - val_accuracy: 0.7571\n",
            "Epoch 104/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.4006 - accuracy: 0.9393 - val_loss: 1.0479 - val_accuracy: 0.7590\n",
            "Epoch 105/500\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3916 - accuracy: 0.9447 - val_loss: 1.0432 - val_accuracy: 0.7571\n",
            "Epoch 106/500\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 0.3867 - accuracy: 0.9412 - val_loss: 1.0438 - val_accuracy: 0.7590\n",
            "Epoch 107/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.3777 - accuracy: 0.9435 - val_loss: 1.0394 - val_accuracy: 0.7609\n",
            "Epoch 108/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.3707 - accuracy: 0.9452 - val_loss: 1.0311 - val_accuracy: 0.7628\n",
            "Epoch 109/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3606 - accuracy: 0.9469 - val_loss: 1.0342 - val_accuracy: 0.7609\n",
            "Epoch 110/500\n",
            "132/132 [==============================] - 4s 31ms/step - loss: 0.3527 - accuracy: 0.9481 - val_loss: 1.0299 - val_accuracy: 0.7571\n",
            "Epoch 111/500\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.3463 - accuracy: 0.9507 - val_loss: 1.0303 - val_accuracy: 0.7552\n",
            "Epoch 112/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3411 - accuracy: 0.9528 - val_loss: 1.0224 - val_accuracy: 0.7628\n",
            "Epoch 113/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3375 - accuracy: 0.9519 - val_loss: 1.0192 - val_accuracy: 0.7590\n",
            "Epoch 114/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3243 - accuracy: 0.9526 - val_loss: 1.0167 - val_accuracy: 0.7609\n",
            "Epoch 115/500\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 0.3203 - accuracy: 0.9547 - val_loss: 1.0133 - val_accuracy: 0.7666\n",
            "Epoch 116/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.3145 - accuracy: 0.9556 - val_loss: 1.0093 - val_accuracy: 0.7666\n",
            "Epoch 117/500\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.3070 - accuracy: 0.9578 - val_loss: 1.0128 - val_accuracy: 0.7685\n",
            "Epoch 118/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3012 - accuracy: 0.9602 - val_loss: 1.0069 - val_accuracy: 0.7685\n",
            "Epoch 119/500\n",
            "132/132 [==============================] - 3s 21ms/step - loss: 0.2962 - accuracy: 0.9587 - val_loss: 1.0051 - val_accuracy: 0.7647\n",
            "Epoch 120/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2918 - accuracy: 0.9592 - val_loss: 1.0022 - val_accuracy: 0.7685\n",
            "Epoch 121/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2847 - accuracy: 0.9602 - val_loss: 1.0014 - val_accuracy: 0.7666\n",
            "Epoch 122/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2799 - accuracy: 0.9618 - val_loss: 1.0005 - val_accuracy: 0.7647\n",
            "Epoch 123/500\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.2722 - accuracy: 0.9632 - val_loss: 0.9976 - val_accuracy: 0.7666\n",
            "Epoch 124/500\n",
            "132/132 [==============================] - 3s 21ms/step - loss: 0.2702 - accuracy: 0.9639 - val_loss: 0.9921 - val_accuracy: 0.7647\n",
            "Epoch 125/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2638 - accuracy: 0.9651 - val_loss: 0.9961 - val_accuracy: 0.7647\n",
            "Epoch 126/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2604 - accuracy: 0.9651 - val_loss: 0.9901 - val_accuracy: 0.7666\n",
            "Epoch 127/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2548 - accuracy: 0.9651 - val_loss: 0.9887 - val_accuracy: 0.7628\n",
            "Epoch 128/500\n",
            "132/132 [==============================] - 3s 24ms/step - loss: 0.2476 - accuracy: 0.9680 - val_loss: 0.9867 - val_accuracy: 0.7704\n",
            "Epoch 129/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2411 - accuracy: 0.9727 - val_loss: 0.9901 - val_accuracy: 0.7666\n",
            "Epoch 130/500\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.2396 - accuracy: 0.9713 - val_loss: 0.9866 - val_accuracy: 0.7647\n",
            "Epoch 131/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2352 - accuracy: 0.9732 - val_loss: 0.9836 - val_accuracy: 0.7742\n",
            "Epoch 132/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2310 - accuracy: 0.9711 - val_loss: 0.9814 - val_accuracy: 0.7723\n",
            "Epoch 133/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.2238 - accuracy: 0.9722 - val_loss: 0.9827 - val_accuracy: 0.7761\n",
            "Epoch 134/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2216 - accuracy: 0.9734 - val_loss: 0.9790 - val_accuracy: 0.7799\n",
            "Epoch 135/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2161 - accuracy: 0.9739 - val_loss: 0.9795 - val_accuracy: 0.7685\n",
            "Epoch 136/500\n",
            "132/132 [==============================] - 3s 22ms/step - loss: 0.2129 - accuracy: 0.9744 - val_loss: 0.9771 - val_accuracy: 0.7761\n",
            "Epoch 137/500\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2081 - accuracy: 0.9765 - val_loss: 0.9823 - val_accuracy: 0.7704\n",
            "Epoch 138/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2027 - accuracy: 0.9770 - val_loss: 0.9768 - val_accuracy: 0.7761\n",
            "Epoch 139/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2013 - accuracy: 0.9775 - val_loss: 0.9740 - val_accuracy: 0.7742\n",
            "Epoch 140/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1976 - accuracy: 0.9775 - val_loss: 0.9725 - val_accuracy: 0.7780\n",
            "Epoch 141/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1931 - accuracy: 0.9760 - val_loss: 0.9721 - val_accuracy: 0.7780\n",
            "Epoch 142/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1901 - accuracy: 0.9791 - val_loss: 0.9730 - val_accuracy: 0.7723\n",
            "Epoch 143/500\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.1859 - accuracy: 0.9813 - val_loss: 0.9718 - val_accuracy: 0.7742\n",
            "Epoch 144/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1822 - accuracy: 0.9822 - val_loss: 0.9672 - val_accuracy: 0.7780\n",
            "Epoch 145/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1772 - accuracy: 0.9813 - val_loss: 0.9718 - val_accuracy: 0.7742\n",
            "Epoch 146/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.1736 - accuracy: 0.9829 - val_loss: 0.9684 - val_accuracy: 0.7761\n",
            "Epoch 147/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.1709 - accuracy: 0.9836 - val_loss: 0.9663 - val_accuracy: 0.7799\n",
            "Epoch 148/500\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.1679 - accuracy: 0.9836 - val_loss: 0.9686 - val_accuracy: 0.7761\n",
            "Epoch 149/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.1633 - accuracy: 0.9836 - val_loss: 0.9667 - val_accuracy: 0.7780\n",
            "Epoch 150/500\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.1606 - accuracy: 0.9829 - val_loss: 0.9611 - val_accuracy: 0.7818\n",
            "Epoch 151/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1569 - accuracy: 0.9843 - val_loss: 0.9636 - val_accuracy: 0.7837\n",
            "Epoch 152/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1553 - accuracy: 0.9843 - val_loss: 0.9653 - val_accuracy: 0.7818\n",
            "Epoch 153/500\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.1519 - accuracy: 0.9843 - val_loss: 0.9670 - val_accuracy: 0.7780\n",
            "Epoch 154/500\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.1475 - accuracy: 0.9862 - val_loss: 0.9680 - val_accuracy: 0.7780\n",
            "Epoch 155/500\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.1449 - accuracy: 0.9853 - val_loss: 0.9614 - val_accuracy: 0.7818\n",
            "Epoch 155: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing loss and accuracy of the model on the test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FksY9EwwHDkd",
        "outputId": "a17ee356-5ec5-40c1-966b-0167124b89ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.8349\n",
            "Loss:  0.6911157965660095\n",
            "Accuracy:  0.8349146246910095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the history of training and its keys\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPdyDruxHIv1",
        "outputId": "45eda505-3639-499f-f6ff-54a9a6ebbfca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "metadata": {
        "id": "shbF_xRlHDqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting of loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iLsoTgHGP7Oq",
        "outputId": "464dc629-f231-4b6d-f456-a4d02cec7f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting of accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1uWqq-CtP-Lq",
        "outputId": "cb54fa8f-3a8f-4f6b-8b5b-d89b9c6fc98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the probability model for testing\n",
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "\n",
        "# predicting test samples\n",
        "predictions = probability_model.predict(raw_test_batch.map(vectorize_text))"
      ],
      "metadata": {
        "id": "YQj61lIMvX-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94491f03-109e-4bb8-9f4f-480cd6f1f8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# showing the first test sample result label\n",
        "np.argmax(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cbhBKR7NYPQ",
        "outputId": "78470c18-88a1-48dc-a0ed-783ce52fdaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# showing the true label of the first test sample\n",
        "test_df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNsnTWVuu3xj",
        "outputId": "569ac4e8-daf9-49f7-d554-33e50aeb069e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         herschel sulfur spring olive night reflective ...\n",
              "label                                           Luggage & Bags\n",
              "label_int                                                   12\n",
              "Name: 3686, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** https://farrokhkarimi.github.io/"
      ],
      "metadata": {
        "id": "CSw7kwIQipyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning  \n",
        "In this section, I will be testing different hyperparameters using Keras RandomSearch.\n",
        "\n",
        "**Editor:** [Roham Zendehdel Nobari](https://github.com/rzninvo\\)"
      ],
      "metadata": {
        "id": "3FCqbIdv1oB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clearing Keras data on RAM.\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "ju2JTm4d6LpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing keras tuner"
      ],
      "metadata": {
        "id": "M5ly7yN3eryE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "id": "BRGkbXd5eu0U",
        "outputId": "6c68505b-584d-4244-cf48-deeff5d80991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.30.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.3.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Changes"
      ],
      "metadata": {
        "id": "ksnnA_l626wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a function for spliting train and test datasets with arbitrary percentages."
      ],
      "metadata": {
        "id": "KZgzLmZxDA-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_test_datasets(dataset, test_size, val_frac):\n",
        "  # splitting dataset to train, validation, and test dataframes\n",
        "  train_df, test_df= train_test_split(dataset, test_size= test_size, random_state=42)\n",
        "  val_df = test_df.sample(frac= val_frac)\n",
        "  test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "  print(f\"Number of samples in training set: {len(train_df)}\")\n",
        "  print(f\"Number of samples in validation set: {len(val_df)}\")\n",
        "  print(f\"Number of samples in test set: {len(test_df)}\")\n",
        "\n",
        "  # extracting texts and labels from dataframes\n",
        "  train_texts = train_df['text']\n",
        "  train_labels = train_df['label_int']\n",
        "  val_texts = val_df['text']\n",
        "  val_labels = val_df['label_int']\n",
        "  test_texts = test_df['text']\n",
        "  test_labels = test_df['label_int']\n",
        "\n",
        "  return {'train_texts': train_texts, 'train_labels': train_labels, 'val_texts': val_texts, 'val_labels': val_labels, 'test_texts': test_texts, 'test_labels': test_labels}"
      ],
      "metadata": {
        "id": "hpH8hAQTBM_S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the batch size tunable."
      ],
      "metadata": {
        "id": "f27WwbtFEWlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_batches(batch_size, dataset_dict):\n",
        "  train_texts = dataset_dict['train_texts']\n",
        "  train_labels = dataset_dict['train_labels']\n",
        "  val_texts = dataset_dict['val_texts']\n",
        "  val_labels = dataset_dict['val_labels']\n",
        "  test_texts = dataset_dict['test_texts']\n",
        "  test_labels = dataset_dict['test_labels']\n",
        "\n",
        "  raw_train_batch = tf.data.Dataset.from_tensor_slices((train_texts, train_labels)).batch(batch_size)\n",
        "  raw_val_batch = tf.data.Dataset.from_tensor_slices((val_texts, val_labels)).batch(batch_size)\n",
        "  raw_test_batch = tf.data.Dataset.from_tensor_slices((test_texts, test_labels)).batch(batch_size)\n",
        "\n",
        "  return {'raw_train_batch': raw_train_batch, 'raw_val_batch': raw_val_batch, 'raw_test_batch': raw_test_batch}"
      ],
      "metadata": {
        "id": "QrGNo_xYDy-1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the parameters of our vectorizer tunable by implementing a method for vectorizing the dataset."
      ],
      "metadata": {
        "id": "g1S0EJ5y5ZjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the text vectorization layer with \"max_features\" words and a maximum \"sequence length\"\n",
        "def create_vectorizer(max_features, sequence_length, train_texts):\n",
        "  vectorize_layer = layers.TextVectorization(\n",
        "      max_tokens=max_features,\n",
        "      output_mode='int',\n",
        "      output_sequence_length=sequence_length\n",
        "  )\n",
        "\n",
        "  # fitting the state of the preprocessing layer to the train set. This will cause the model to build an index of strings to integers.\n",
        "  vectorize_layer.adapt(train_texts)\n",
        "\n",
        "  return vectorize_layer"
      ],
      "metadata": {
        "id": "5SGCWjnu1na_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assembling all the functions together and vectorizing the dataset with tunable parameters\n",
        "def vectorize_dataset(max_features, sequence_length, train_texts, raw_dataset_batch_dict):\n",
        "\n",
        "  raw_train_batch = raw_dataset_batch_dict['raw_train_batch']\n",
        "  raw_val_batch = raw_dataset_batch_dict['raw_val_batch']\n",
        "  raw_test_batch = raw_dataset_batch_dict['raw_test_batch']\n",
        "\n",
        "  #Creating the vectorizer\n",
        "  vectorize_layer = create_vectorizer(max_features, sequence_length, train_texts)\n",
        "\n",
        "  def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "  train_ds = raw_train_batch.map(vectorize_text)\n",
        "  val_ds = raw_val_batch.map(vectorize_text)\n",
        "  test_ds = raw_test_batch.map(vectorize_text)\n",
        "\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "  train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "  test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return {'train_ds': train_ds, 'val_ds': val_ds, 'test_ds': test_ds}"
      ],
      "metadata": {
        "id": "yMhRTCZ8E_S6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the tunable model\n",
        "In this section I'll assemble all the functions into a  HyperModel class containing build and fit methods with tunable parameters."
      ],
      "metadata": {
        "id": "Q_gLXCNkIUqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import keras_tuner\n",
        "\n",
        "#Untunable parameters\n",
        "num_of_labels = 20\n",
        "val_frac = 0.5\n",
        "test_size = 0.2\n",
        "\n",
        "#Defining the HyperModel class\n",
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "    #Defining the build method which builds and compiles a model with tunable hyperparameters.\n",
        "\n",
        "    def build(self, hp):\n",
        "      #Model hyperparameters\n",
        "      dropout_rate1 = hp.Float('dropout_rate1', min_value=0.1, max_value=0.5, step=0.05)\n",
        "      dropout_rate2 = hp.Float('dropout_rate2', min_value=0.1, max_value=0.5, step=0.05)\n",
        "      embedding_dim = hp.Int('embedding_dim', min_value=32, max_value=256, step=8)\n",
        "      model_optimizer = hp.Choice('optimizer', ['Adam'], default='Adam') #Tested SGD and RMSprop. Didn't get good results\n",
        "      learn_rate = hp.Choice('learn_rate', [0.001, 0.01, 0.1, 0.2, 0.3], default=0.001)\n",
        "      #momentum = hp.Choice('momentum', [0.0, 0.2, 0.4, 0.6, 0.8, 0.9], default=0.0)\n",
        "      '''if model_optimizer in ['SGD', 'RMSprop']:\n",
        "        optimizer = getattr(tf.keras.optimizers, model_optimizer)(learning_rate=learn_rate, momentum=momentum)\n",
        "      else:'''\n",
        "      optimizer = getattr(tf.keras.optimizers, model_optimizer)(learning_rate=learn_rate)\n",
        "      #Preprocessing hyperparameters\n",
        "      batch_size = hp.Int('batch_size', min_value=32, max_value=128, step=16)\n",
        "      max_features = hp.Int('max_features', min_value=19000, max_value=20000, step=1000)\n",
        "      sequence_length = hp.Choice('sequence_length', [310, 350], default=310)\n",
        "      \n",
        "      model = keras.Sequential([\n",
        "        layers.Embedding(max_features + 1, embedding_dim),\n",
        "        layers.Dropout(dropout_rate1),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(dropout_rate2),\n",
        "        layers.Dense(num_of_labels)])\n",
        "\n",
        "      model.compile(optimizer=model_optimizer,\n",
        "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                    metrics=['accuracy'])\n",
        "      return model\n",
        "\n",
        "    #Defining the fit method for preprocessing the dataset with tunable parameters and fitting it to the model\n",
        "    def fit(self, hp, model, dataset, validation_data=None, **kwargs):\n",
        "      #Preprocessing hyperparameters\n",
        "      batch_size = hp.get('batch_size')\n",
        "      max_features = hp.get('max_features')\n",
        "      sequence_length = hp.get('sequence_length')\n",
        "\n",
        "      #Preprocessing the data\n",
        "      dataset_dict = split_train_test_datasets(dataset, test_size, val_frac)\n",
        "      raw_dataset_batch_dict = create_dataset_batches(batch_size, dataset_dict)\n",
        "      final_ds = vectorize_dataset(max_features, sequence_length, dataset_dict['train_texts'], raw_dataset_batch_dict)\n",
        "\n",
        "      return model.fit(\n",
        "          final_ds['train_ds'],\n",
        "          validation_data=final_ds['val_ds'],\n",
        "          **kwargs,\n",
        "      )"
      ],
      "metadata": {
        "id": "PzrwQ2OhIed-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer Selector Function"
      ],
      "metadata": {
        "id": "Rh_xbaxpmBnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting RandomSearch\n",
        "Building the tuner and starting our RandomSearch"
      ],
      "metadata": {
        "id": "hj1Z5Psqdi3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=60,\n",
        "    overwrite=True,\n",
        "    directory=\"my_projects\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=5,\n",
        "                                            verbose=1)\n",
        "\n",
        "tuner.search(dataset, epochs=500, callbacks=[callback])"
      ],
      "metadata": {
        "id": "tH_Q71EwbBFT",
        "outputId": "22c7b16f-1320-40be-a4fe-e6b80178a985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 60 Complete [00h 01m 19s]\n",
            "val_accuracy: 0.8292220234870911\n",
            "\n",
            "Best val_accuracy So Far: 0.8633776307106018\n",
            "Total elapsed time: 01h 32m 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "RonEKw7dSQDt",
        "outputId": "7b2b3bbe-da01-4a61-8faf-5c92f84462cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae7185f22d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tuner' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing other models"
      ],
      "metadata": {
        "id": "XZ8LwyqF_OY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using pretrained embeddings\n",
        "In this section we'll test our optimal hyperparameters with a pretrained embedding library called GloVe"
      ],
      "metadata": {
        "id": "uSTrllg8_k1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading the GloVe word embedding\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "BD02Uh-X_TKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opening the downloaded GloVe word embedding file and counting the word vectors."
      ],
      "metadata": {
        "id": "w3ins7fLAtw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_to_glove_file = os.path.join(\n",
        "    \"glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "id": "_U8SadZQAVk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorize_layer.get_vocabulary()\n",
        "vocab_size = len(vocab)\n",
        "word_index = dict(zip(vocab, range(vocab_size)))\n",
        "num_tokens = vocab_size + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "xwj4lWHXEqCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "embedding_dim = 100\n",
        "num_of_labels = 20\n",
        "\n",
        "model_new = tf.keras.Sequential([\n",
        "  layers.Embedding(vocab_size + 2, embedding_dim),\n",
        "  layers.Conv1D(64, 5, activation=\"relu\"),\n",
        "  layers.MaxPooling1D(5),\n",
        "  layers.Conv1D(128, 5, activation=\"relu\"),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dense(128, activation=\"relu\"),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Dense(num_of_labels)])\n",
        "\n",
        "model_new.summary()"
      ],
      "metadata": {
        "id": "EqM2D6cHEU8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model compilation\n",
        "model_new.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rqs_AMZpQKT0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}